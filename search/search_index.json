{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to HepTrackTool","text":"<p>This package provides tools for track reconstruction using graphs and ML.</p>"},{"location":"#modules","title":"Modules","text":"<ul> <li>IO</li> <li>Models</li> <li>Tools</li> </ul>"},{"location":"dev/","title":"Instructions for developers","text":"<p>We use Poetry for handling dependencies and packaging.</p> <pre><code>poetry install --all-groups\n</code></pre> <p>Docstrings follows the Google style guide. You can find an example takend from Napoleon. <pre><code># -*- coding: utf-8 -*-\n\"\"\"Example Google style docstrings.\n\nThis module demonstrates documentation as specified by the `Google Python\nStyle Guide`_. Docstrings may extend over multiple lines. Sections are created\nwith a section header and a colon followed by a block of indented text.\n\nExample:\n    Examples can be given using either the ``Example`` or ``Examples``\n    sections. Sections support any reStructuredText formatting, including\n    literal blocks::\n\n        $ python example_google.py\n\nSection breaks are created by resuming unindented text. Section breaks\nare also implicitly created anytime a new section starts.\n\nAttributes:\n    module_level_variable1 (int): Module level variables may be documented in\n        either the ``Attributes`` section of the module docstring, or in an\n        inline docstring immediately following the variable.\n\n        Either form is acceptable, but the two should not be mixed. Choose\n        one convention to document module level variables and be consistent\n        with it.\n\nTodo:\n    * For module TODOs\n    * You have to also use ``sphinx.ext.todo`` extension\n\n.. _Google Python Style Guide:\n   http://google.github.io/styleguide/pyguide.html\n\n\"\"\"\n\nmodule_level_variable1 = 12345\n\nmodule_level_variable2 = 98765\n\"\"\"int: Module level variable documented inline.\n\nThe docstring may span multiple lines. The type may optionally be specified\non the first line, separated by a colon.\n\"\"\"\n\n\ndef function_with_types_in_docstring(param1, param2):\n    \"\"\"Example function with types documented in the docstring.\n\n    `PEP 484`_ type annotations are supported. If attribute, parameter, and\n    return types are annotated according to `PEP 484`_, they do not need to be\n    included in the docstring:\n\n    Args:\n        param1 (int): The first parameter.\n        param2 (str): The second parameter.\n\n    Returns:\n        bool: The return value. True for success, False otherwise.\n\n    .. _PEP 484:\n        https://www.python.org/dev/peps/pep-0484/\n\n    \"\"\"\n\n\ndef function_with_pep484_type_annotations(param1: int, param2: str) -&gt; bool:\n    \"\"\"Example function with PEP 484 type annotations.\n\n    Args:\n        param1: The first parameter.\n        param2: The second parameter.\n\n    Returns:\n        The return value. True for success, False otherwise.\n\n    \"\"\"\n\n\ndef module_level_function(param1, param2=None, *args, **kwargs):\n    \"\"\"This is an example of a module level function.\n\n    Function parameters should be documented in the ``Args`` section. The name\n    of each parameter is required. The type and description of each parameter\n    is optional, but should be included if not obvious.\n\n    If \\*args or \\*\\*kwargs are accepted,\n    they should be listed as ``*args`` and ``**kwargs``.\n\n    The format for a parameter is::\n\n        name (type): description\n            The description may span multiple lines. Following\n            lines should be indented. The \"(type)\" is optional.\n\n            Multiple paragraphs are supported in parameter\n            descriptions.\n\n    Args:\n        param1 (int): The first parameter.\n        param2 (:obj:`str`, optional): The second parameter. Defaults to None.\n            Second line of description should be indented.\n        *args: Variable length argument list.\n        **kwargs: Arbitrary keyword arguments.\n\n    Returns:\n        bool: True if successful, False otherwise.\n\n        The return type is optional and may be specified at the beginning of\n        the ``Returns`` section followed by a colon.\n\n        The ``Returns`` section may span multiple lines and paragraphs.\n        Following lines should be indented to match the first line.\n\n        The ``Returns`` section supports any reStructuredText formatting,\n        including literal blocks::\n\n            {\n                'param1': param1,\n                'param2': param2\n            }\n\n    Raises:\n        AttributeError: The ``Raises`` section is a list of all exceptions\n            that are relevant to the interface.\n        ValueError: If `param2` is equal to `param1`.\n\n    \"\"\"\n    if param1 == param2:\n        raise ValueError('param1 may not be equal to param2')\n    return True\n\n\ndef example_generator(n):\n    \"\"\"Generators have a ``Yields`` section instead of a ``Returns`` section.\n\n    Args:\n        n (int): The upper limit of the range to generate, from 0 to `n` - 1.\n\n    Yields:\n        int: The next number in the range of 0 to `n` - 1.\n\n    Examples:\n        Examples should be written in doctest format, and should illustrate how\n        to use the function.\n\n        &gt;&gt;&gt; print([i for i in example_generator(4)])\n        [0, 1, 2, 3]\n\n    \"\"\"\n    for i in range(n):\n        yield i\n\n\nclass ExampleError(Exception):\n    \"\"\"Exceptions are documented in the same way as classes.\n\n    The __init__ method may be documented in either the class level\n    docstring, or as a docstring on the __init__ method itself.\n\n    Either form is acceptable, but the two should not be mixed. Choose one\n    convention to document the __init__ method and be consistent with it.\n\n    Note:\n        Do not include the `self` parameter in the ``Args`` section.\n\n    Args:\n        msg (str): Human readable string describing the exception.\n        code (:obj:`int`, optional): Error code.\n\n    Attributes:\n        msg (str): Human readable string describing the exception.\n        code (int): Exception error code.\n\n    \"\"\"\n\n    def __init__(self, msg, code):\n        self.msg = msg\n        self.code = code\n\n\nclass ExampleClass(object):\n    \"\"\"The summary line for a class docstring should fit on one line.\n\n    If the class has public attributes, they may be documented here\n    in an ``Attributes`` section and follow the same formatting as a\n    function's ``Args`` section. Alternatively, attributes may be documented\n    inline with the attribute's declaration (see __init__ method below).\n\n    Properties created with the ``@property`` decorator should be documented\n    in the property's getter method.\n\n    Attributes:\n        attr1 (str): Description of `attr1`.\n        attr2 (:obj:`int`, optional): Description of `attr2`.\n\n    \"\"\"\n\n    def __init__(self, param1, param2, param3):\n        \"\"\"Example of docstring on the __init__ method.\n\n        The __init__ method may be documented in either the class level\n        docstring, or as a docstring on the __init__ method itself.\n\n        Either form is acceptable, but the two should not be mixed. Choose one\n        convention to document the __init__ method and be consistent with it.\n\n        Note:\n            Do not include the `self` parameter in the ``Args`` section.\n\n        Args:\n            param1 (str): Description of `param1`.\n            param2 (:obj:`int`, optional): Description of `param2`. Multiple\n                lines are supported.\n            param3 (:obj:`list` of :obj:`str`): Description of `param3`.\n\n        \"\"\"\n        self.attr1 = param1\n        self.attr2 = param2\n        self.attr3 = param3  #: Doc comment *inline* with attribute\n\n        #: list of str: Doc comment *before* attribute, with type specified\n        self.attr4 = ['attr4']\n\n        self.attr5 = None\n        \"\"\"str: Docstring *after* attribute, with type specified.\"\"\"\n\n    @property\n    def readonly_property(self):\n        \"\"\"str: Properties should be documented in their getter method.\"\"\"\n        return 'readonly_property'\n\n    @property\n    def readwrite_property(self):\n        \"\"\":obj:`list` of :obj:`str`: Properties with both a getter and setter\n        should only be documented in their getter method.\n\n        If the setter method contains notable behavior, it should be\n        mentioned here.\n        \"\"\"\n        return ['readwrite_property']\n\n    @readwrite_property.setter\n    def readwrite_property(self, value):\n        value\n\n    def example_method(self, param1, param2):\n        \"\"\"Class methods are similar to regular functions.\n\n        Note:\n            Do not include the `self` parameter in the ``Args`` section.\n\n        Args:\n            param1: The first parameter.\n            param2: The second parameter.\n\n        Returns:\n            True if successful, False otherwise.\n\n        \"\"\"\n        return True\n\n    def __special__(self):\n        \"\"\"By default special members with docstrings are not included.\n\n        Special members are any methods or attributes that start with and\n        end with a double underscore. Any special member with a docstring\n        will be included in the output, if\n        ``napoleon_include_special_with_doc`` is set to True.\n\n        This behavior can be enabled by changing the following setting in\n        Sphinx's conf.py::\n\n            napoleon_include_special_with_doc = True\n\n        \"\"\"\n        pass\n\n    def __special_without_docstring__(self):\n        pass\n\n    def _private(self):\n        \"\"\"By default private members are not included.\n\n        Private members are any methods or attributes that start with an\n        underscore and are *not* special. By default they are not included\n        in the output.\n\n        This behavior can be changed such that private members *are* included\n        by changing the following setting in Sphinx's conf.py::\n\n            napoleon_include_private_with_doc = True\n\n        \"\"\"\n        pass\n\n    def _private_without_docstring(self):\n        pass\n</code></pre></p>"},{"location":"api/heptracktool/io/","title":"heptracktool.io","text":""},{"location":"api/heptracktool/io/#actsreader","title":"ActsReader","text":""},{"location":"api/heptracktool/io/#heptracktool.io.acts.ActsReader","title":"<code>ActsReader</code>","text":"<p>               Bases: <code>BaseTrackDataReader</code></p> Source code in <code>src/heptracktool/io/acts.py</code> <pre><code>class ActsReader(BaseTrackDataReader):\n    def __init__(\n        self,\n        inputdir: str,\n        output_dir: str | None = None,\n        overwrite: bool = True,\n        name: str = \"ActsReader\",\n        spname: str = \"spacepoint\",\n    ):\n        super().__init__(inputdir, output_dir, overwrite, name)\n        self.spname = spname\n\n        # count how many events in the directory\n        all_evts = glob.glob(os.path.join(self.basedir, f\"event*-{spname}.csv\"))\n\n        pattern = f\"event([0-9]*)-{spname}.csv\"\n        self.all_evtids = sorted(\n            [\n                int(re.search(pattern, os.path.basename(x)).group(1).strip())\n                for x in all_evts\n            ]\n        )\n        self.nevts = len(self.all_evtids)\n        print(f\"total {self.nevts} events in directory: {self.basedir}\")\n\n    def read(self, evtid: int) -&gt; bool:\n        \"\"\"Read one event from the input directory.\n\n        Return:\n            MeasurementData\n        \"\"\"\n        if (evtid is None or evtid &lt; 1) and self.nevts &gt; 0:\n            evtid = self.all_evtids[0]\n\n        prefix = os.path.join(self.basedir, f\"event{evtid:09d}\")\n        hit_fname = f\"{prefix}-hits.csv\"\n        measurements_fname = f\"{prefix}-measurements.csv\"\n        measurements2hits_fname = f\"{prefix}-measurement-simhit-map.csv\"\n        sp_fname = f\"{prefix}-{self.spname}.csv\"\n        p_name = f\"{prefix}-particles_final.csv\"\n\n        # read hit files\n        hits = pd.read_csv(hit_fname)\n        hits = hits[hits.columns[:-1]]\n        hits = hits.reset_index().rename(columns={\"index\": \"hit_id\"})\n\n        # read measurements, maps to hits, and spacepoints\n        measurements = pd.read_csv(measurements_fname)\n        meas2hits = pd.read_csv(measurements2hits_fname)\n        sp = pd.read_csv(sp_fname)\n\n        # read particles and add more variables for performance evaluation\n        particles = pd.read_csv(p_name)\n        pt = np.sqrt(particles.px**2 + particles.py**2)\n        momentum = np.sqrt(pt**2 + particles.pz**2)\n        theta = np.arccos(particles.pz / momentum)\n        eta = -np.log(np.tan(0.5 * theta))\n        radius = np.sqrt(particles.vx**2 + particles.vy**2)\n        particles = particles.assign(pt=pt, radius=radius, eta=eta)\n\n        # read cluster information\n        cell_fname = f\"{prefix}-cells.csv\"\n        cells = pd.read_csv(cell_fname)\n\n        # calculate cluster shape information\n        direction_count_u = cells.groupby([\"hit_id\"]).channel0.agg([\"min\", \"max\"])\n        direction_count_v = cells.groupby([\"hit_id\"]).channel1.agg([\"min\", \"max\"])\n        nb_u = direction_count_u[\"max\"] - direction_count_u[\"min\"] + 1\n        nb_v = direction_count_v[\"max\"] - direction_count_v[\"min\"] + 1\n        hit_cells = cells.groupby([\"hit_id\"]).value.count().values\n        hit_value = cells.groupby([\"hit_id\"]).value.sum().values\n        # as I don't access to the rotation matrix and the pixel pitches,\n        # I can't calculate cluster's local/global position\n        sp = sp.assign(len_u=nb_u, len_v=nb_v, cell_count=hit_cells, cell_val=hit_value)\n\n        sp_hits = sp.merge(meas2hits, on=\"measurement_id\", how=\"left\").merge(\n            hits, on=\"hit_id\", how=\"left\"\n        )\n        sp_hits = sp_hits.merge(\n            particles[[\"particle_id\", \"vx\", \"vy\", \"vz\"]], on=\"particle_id\", how=\"left\"\n        )\n\n        r = np.sqrt(sp_hits.x**2 + sp_hits.y**2)\n        phi = np.arctan2(sp_hits.y, sp_hits.x)\n        sp_hits = sp_hits.assign(r=r, phi=phi)\n\n        sp_hits = sp_hits.assign(\n            R=np.sqrt(\n                (sp_hits.x - sp_hits.vx) ** 2\n                + (sp_hits.y - sp_hits.vy) ** 2\n                + (sp_hits.z - sp_hits.vz) ** 2\n            )\n        )\n        sp_hits = (\n            sp_hits.sort_values(\"R\").reset_index(drop=True).reset_index(drop=False)\n        )\n\n        edges = make_true_edges(sp_hits)\n        self.particles = particles\n        self.clusters = measurements\n        self.spacepoints = sp_hits\n        self.true_edges = edges\n\n        return True\n</code></pre>"},{"location":"api/heptracktool/io/#heptracktool.io.acts.ActsReader.read","title":"<code>read(evtid)</code>","text":"<p>Read one event from the input directory.</p> Return <p>MeasurementData</p> Source code in <code>src/heptracktool/io/acts.py</code> <pre><code>def read(self, evtid: int) -&gt; bool:\n    \"\"\"Read one event from the input directory.\n\n    Return:\n        MeasurementData\n    \"\"\"\n    if (evtid is None or evtid &lt; 1) and self.nevts &gt; 0:\n        evtid = self.all_evtids[0]\n\n    prefix = os.path.join(self.basedir, f\"event{evtid:09d}\")\n    hit_fname = f\"{prefix}-hits.csv\"\n    measurements_fname = f\"{prefix}-measurements.csv\"\n    measurements2hits_fname = f\"{prefix}-measurement-simhit-map.csv\"\n    sp_fname = f\"{prefix}-{self.spname}.csv\"\n    p_name = f\"{prefix}-particles_final.csv\"\n\n    # read hit files\n    hits = pd.read_csv(hit_fname)\n    hits = hits[hits.columns[:-1]]\n    hits = hits.reset_index().rename(columns={\"index\": \"hit_id\"})\n\n    # read measurements, maps to hits, and spacepoints\n    measurements = pd.read_csv(measurements_fname)\n    meas2hits = pd.read_csv(measurements2hits_fname)\n    sp = pd.read_csv(sp_fname)\n\n    # read particles and add more variables for performance evaluation\n    particles = pd.read_csv(p_name)\n    pt = np.sqrt(particles.px**2 + particles.py**2)\n    momentum = np.sqrt(pt**2 + particles.pz**2)\n    theta = np.arccos(particles.pz / momentum)\n    eta = -np.log(np.tan(0.5 * theta))\n    radius = np.sqrt(particles.vx**2 + particles.vy**2)\n    particles = particles.assign(pt=pt, radius=radius, eta=eta)\n\n    # read cluster information\n    cell_fname = f\"{prefix}-cells.csv\"\n    cells = pd.read_csv(cell_fname)\n\n    # calculate cluster shape information\n    direction_count_u = cells.groupby([\"hit_id\"]).channel0.agg([\"min\", \"max\"])\n    direction_count_v = cells.groupby([\"hit_id\"]).channel1.agg([\"min\", \"max\"])\n    nb_u = direction_count_u[\"max\"] - direction_count_u[\"min\"] + 1\n    nb_v = direction_count_v[\"max\"] - direction_count_v[\"min\"] + 1\n    hit_cells = cells.groupby([\"hit_id\"]).value.count().values\n    hit_value = cells.groupby([\"hit_id\"]).value.sum().values\n    # as I don't access to the rotation matrix and the pixel pitches,\n    # I can't calculate cluster's local/global position\n    sp = sp.assign(len_u=nb_u, len_v=nb_v, cell_count=hit_cells, cell_val=hit_value)\n\n    sp_hits = sp.merge(meas2hits, on=\"measurement_id\", how=\"left\").merge(\n        hits, on=\"hit_id\", how=\"left\"\n    )\n    sp_hits = sp_hits.merge(\n        particles[[\"particle_id\", \"vx\", \"vy\", \"vz\"]], on=\"particle_id\", how=\"left\"\n    )\n\n    r = np.sqrt(sp_hits.x**2 + sp_hits.y**2)\n    phi = np.arctan2(sp_hits.y, sp_hits.x)\n    sp_hits = sp_hits.assign(r=r, phi=phi)\n\n    sp_hits = sp_hits.assign(\n        R=np.sqrt(\n            (sp_hits.x - sp_hits.vx) ** 2\n            + (sp_hits.y - sp_hits.vy) ** 2\n            + (sp_hits.z - sp_hits.vz) ** 2\n        )\n    )\n    sp_hits = (\n        sp_hits.sort_values(\"R\").reset_index(drop=True).reset_index(drop=False)\n    )\n\n    edges = make_true_edges(sp_hits)\n    self.particles = particles\n    self.clusters = measurements\n    self.spacepoints = sp_hits\n    self.true_edges = edges\n\n    return True\n</code></pre>"},{"location":"api/heptracktool/models/","title":"<code>heptracktool.models</code>","text":""},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning","title":"<code>metric_learning</code>","text":""},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning","title":"<code>MetricLearning</code>","text":"<p>               Bases: <code>LightningModule</code></p> Source code in <code>src/heptracktool/models/metric_learning.py</code> <pre><code>class MetricLearning(LightningModule):\n    def __init__(\n        self,\n        model,\n        optimizer,\n        scheduler,\n        r_max: float = 0.1,\n        k_max: int = 1000,\n        scheduler_interval: str = \"epoch\",\n        scheduler_frequency: int = 1,\n        scheduler_monitor: str = \"val/reco_error\",\n    ):\n        super().__init__()\n        self.save_hyperparameters(\n            logger=False,\n            ignore=[\"model\", \"optimizer\", \"scheduler\"],\n        )\n        self.network = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n\n        self.delta_r = 0.01\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        x_out = self.network(x)\n        return F.normalize(x_out)\n\n    def configure_optimizers(self):\n        opt = self.optimizer(params=self.parameters())\n        if self.scheduler is not None:\n            sch = self.scheduler(optimizer=opt)\n            return {\n                \"optimizer\": opt,\n                \"lr_scheduler\": {\n                    \"scheduler\": sch,\n                    \"interval\": self.hparams.scheduler_interval,\n                    \"frequency\": self.hparams.scheduler_frequency,\n                    \"monitor\": self.hparams.scheduler_monitor,\n                },\n            }\n        return {\"optimizer\": opt, \"frequency\": 1}\n\n    def on_train_batch_start(self, batch: Data, batch_idx: int) -&gt; None:\n        # prepare the edge list for the current batch.\n        # and their labels.\n\n        assert hasattr(batch, \"track_edges\")\n        assert hasattr(batch, \"x\")\n\n        knn_edges = self._get_knn_edges(batch)\n        edge_list = torch.cat([batch.track_edges, knn_edges], dim=1)\n        self._order_edge_direction(batch.R, edge_list)\n\n        # remove duplicate edges.\n        edge_list = torch.unique(edge_list, dim=1)\n\n        # randomly shuffle the edges\n        edge_list = edge_list[:, torch.randperm(edge_list.shape[1])]\n\n        # create the labels for the edges\n        # and truth to predict labels.\n        edge_y, truth_map = graph_intersection(\n            edge_list,\n            batch.track_edges,\n            return_truth_to_pred=True,\n        )\n\n        batch.edge_index = edge_list\n        batch.y = edge_y\n        batch.truth_map = truth_map\n        batch.edge_weights = self._get_edge_weights(batch)\n\n    def training_step(self, batch: Data, batch_idx: int) -&gt; torch.Tensor:\n        embedding = self(batch.x)\n        loss = self._compute_loss(batch, embedding).float()\n        self.log(\"train_loss\", loss, batch_size=1, prog_bar=True)\n        return loss\n\n    def _compute_loss(self, batch, embedding: torch.Tensor) -&gt; torch.Tensor:\n        # compute the distances between the nodes in the edge list\n        pred_edges = batch.edge_index\n        d = self._get_distances(embedding, pred_edges)\n\n        # compute the loss\n        y = batch.y\n        pos_mask = y == 1\n        neg_mask = y == 0\n\n        pos_loss = torch.mean(d[pos_mask])\n        neg_loss = torch.mean(F.relu(self.hparams.r_max - d[neg_mask]))\n\n        loss = pos_loss + neg_loss\n        return loss\n\n    def _get_distances(self, embedding, pred_edges):\n        reference = embedding[pred_edges[1]]\n        neighbors = embedding[pred_edges[0]]\n        d = torch.sum((reference - neighbors) ** 2, dim=-1)\n        return d\n\n    def _order_edge_direction(self, R: torch.Tensor, edge_list: torch.Tensor):\n        # make sure edge (a, b) where a is always closer to beam spot than b\n        mask = (R[edge_list[0]] &gt; R[edge_list[1]]) | (\n            R[edge_list[0]] == R[edge_list[1]] &amp; (edge_list[0] &gt; edge_list[1])\n        )\n        edge_list[:, mask] = edge_list[:, mask].flip(0)\n\n    def _get_knn_edges(self, batch: Data) -&gt; torch.Tensor:\n        \"\"\"Get knn edges for the current batch and return them with their labels.\"\"\"\n\n        self.eval()\n        # create hard negative edges using FRNN.\n        with torch.no_grad():\n            embedding = self(batch.x)\n\n        knn_edges = build_edges(\n            embedding,\n            embedding,\n            r_max=self.hparams.r_max + self.delta_r,\n            k_max=self.hparams.k_max,\n            backend=\"FRNN\",\n        )\n        self.train()\n        return knn_edges\n\n    def _get_edge_weights(self, batch: Data) -&gt; torch.Tensor:\n        \"\"\"assign weigths to true and false edges.\"\"\"\n        assert hasattr(batch, \"edge_index\")\n        assert hasattr(batch, \"y\")\n\n        # get the weights for the edges\n        edge_weights = torch.ones(batch.edge_index.shape[1])\n        edge_weights[batch.y == 0] = self.hparams.r_max\n\n        return edge_weights\n</code></pre>"},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning.delta_r","title":"<code>delta_r = 0.01</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning.network","title":"<code>network = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning.optimizer","title":"<code>optimizer = optimizer</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning.scheduler","title":"<code>scheduler = scheduler</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning.__init__","title":"<code>__init__(model, optimizer, scheduler, r_max=0.1, k_max=1000, scheduler_interval='epoch', scheduler_frequency=1, scheduler_monitor='val/reco_error')</code>","text":"Source code in <code>src/heptracktool/models/metric_learning.py</code> <pre><code>def __init__(\n    self,\n    model,\n    optimizer,\n    scheduler,\n    r_max: float = 0.1,\n    k_max: int = 1000,\n    scheduler_interval: str = \"epoch\",\n    scheduler_frequency: int = 1,\n    scheduler_monitor: str = \"val/reco_error\",\n):\n    super().__init__()\n    self.save_hyperparameters(\n        logger=False,\n        ignore=[\"model\", \"optimizer\", \"scheduler\"],\n    )\n    self.network = model\n    self.optimizer = optimizer\n    self.scheduler = scheduler\n\n    self.delta_r = 0.01\n</code></pre>"},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"Source code in <code>src/heptracktool/models/metric_learning.py</code> <pre><code>def configure_optimizers(self):\n    opt = self.optimizer(params=self.parameters())\n    if self.scheduler is not None:\n        sch = self.scheduler(optimizer=opt)\n        return {\n            \"optimizer\": opt,\n            \"lr_scheduler\": {\n                \"scheduler\": sch,\n                \"interval\": self.hparams.scheduler_interval,\n                \"frequency\": self.hparams.scheduler_frequency,\n                \"monitor\": self.hparams.scheduler_monitor,\n            },\n        }\n    return {\"optimizer\": opt, \"frequency\": 1}\n</code></pre>"},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning.forward","title":"<code>forward(x)</code>","text":"Source code in <code>src/heptracktool/models/metric_learning.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    x_out = self.network(x)\n    return F.normalize(x_out)\n</code></pre>"},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning.on_train_batch_start","title":"<code>on_train_batch_start(batch, batch_idx)</code>","text":"Source code in <code>src/heptracktool/models/metric_learning.py</code> <pre><code>def on_train_batch_start(self, batch: Data, batch_idx: int) -&gt; None:\n    # prepare the edge list for the current batch.\n    # and their labels.\n\n    assert hasattr(batch, \"track_edges\")\n    assert hasattr(batch, \"x\")\n\n    knn_edges = self._get_knn_edges(batch)\n    edge_list = torch.cat([batch.track_edges, knn_edges], dim=1)\n    self._order_edge_direction(batch.R, edge_list)\n\n    # remove duplicate edges.\n    edge_list = torch.unique(edge_list, dim=1)\n\n    # randomly shuffle the edges\n    edge_list = edge_list[:, torch.randperm(edge_list.shape[1])]\n\n    # create the labels for the edges\n    # and truth to predict labels.\n    edge_y, truth_map = graph_intersection(\n        edge_list,\n        batch.track_edges,\n        return_truth_to_pred=True,\n    )\n\n    batch.edge_index = edge_list\n    batch.y = edge_y\n    batch.truth_map = truth_map\n    batch.edge_weights = self._get_edge_weights(batch)\n</code></pre>"},{"location":"api/heptracktool/models/#heptracktool.models.metric_learning.MetricLearning.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"Source code in <code>src/heptracktool/models/metric_learning.py</code> <pre><code>def training_step(self, batch: Data, batch_idx: int) -&gt; torch.Tensor:\n    embedding = self(batch.x)\n    loss = self._compute_loss(batch, embedding).float()\n    self.log(\"train_loss\", loss, batch_size=1, prog_bar=True)\n    return loss\n</code></pre>"},{"location":"api/heptracktool/tools/","title":"Tools","text":""},{"location":"api/heptracktool/tools/#heptracktool.tools.analyze_track_data.TrackAnalyzer","title":"<code>TrackAnalyzer</code>","text":"Source code in <code>src/heptracktool/tools/analyze_track_data.py</code> <pre><code>class TrackAnalyzer:\n    def __init__(self, reader: BaseTrackDataReader):\n        self.reader = reader\n\n    def study_cluster_features(self, evtid: int = 0):\n        \"\"\"Study the cluster features\"\"\"\n        self.reader.read(evtid)\n        if self.reader.clusters is None:\n            print(f\"No cluster information found in {self.reader.name} for event {evtid}.\")\n\n        clusters = self.reader.clusters\n        print(\"Number of clusters: \", clusters.shape[0])\n        pixel_clusters = clusters[clusters[\"hardware\"] == \"PIXEL\"]\n        strip_clusters = clusters[clusters[\"hardware\"] == \"STRIP\"]\n        print(\"Number of pixel clusters: \", pixel_clusters.shape[0])\n        print(\"Number of strip clusters: \", strip_clusters.shape[0])\n\n        # number of pixels per cluster\n        _, ax = create_figure()\n        config = dict(bins=31, range=(-0.5, 30.5), histtype=\"step\", lw=2, alpha=0.8)\n        ax.hist(pixel_clusters[\"pixel_count\"], label=\"Pixel clusters\", **config)\n        ax.hist(strip_clusters[\"pixel_count\"], label=\"Strip clusters\", **config)\n        ax.set_xlabel(\"# of Pixels per cluster\")\n        plt.legend()\n        plt.show()\n\n        # number of charges per cluster\n        print(\"Charge information is not available for strip clusters\")\n        _, ax = create_figure()\n        config = dict(bins=51, range=(-0.5, 50.5), histtype=\"step\", lw=2)\n        ax.hist(pixel_clusters[\"charge_count\"], label=\"Pixel clusters\", **config)\n        ax.set_xlabel(\"# of Charges per cluster\")\n        add_mean_std(pixel_clusters[\"charge_count\"], 15, 15000, ax, dy=2500)\n        plt.legend()\n        plt.show()\n\n        # cluster position\n        _, ax = create_figure()\n        config = dict(bins=600, range=(-3000, 3000), histtype=\"step\", lw=2, alpha=0.8)\n        ax.hist(pixel_clusters[\"cluster_x\"], label=\"pixel x\", **config)\n        ax.hist(pixel_clusters[\"cluster_y\"], label=\"pixel y\", **config)\n        ax.hist(pixel_clusters[\"cluster_z\"], label=\"pixel z\", **config)\n        ax.hist(strip_clusters[\"cluster_x\"], label=\"strip x\", **config, linestyle=\"--\")\n        ax.hist(strip_clusters[\"cluster_y\"], label=\"strip y\", **config, linestyle=\"--\")\n        ax.hist(strip_clusters[\"cluster_z\"], label=\"strip z\", **config, linestyle=\"--\")\n        ax.set_xlabel(\"Cluster position [mm]\")\n        plt.legend()\n        plt.show()\n\n        # # local directions of clusters\n        # _, ax = create_figure()\n        # config = dict(bins=50, range=(0, 30.0), histtype=\"step\", lw=2, alpha=0.8)\n        # ax.hist(pixel_clusters[\"localDir0\"], label=\"pixel x\", **config)\n        # ax.hist(pixel_clusters[\"localDir1\"], label=\"pixel y\", **config)\n        # ax.hist(pixel_clusters[\"localDir2\"], label=\"pixel z\", **config)\n        # ax.hist(strip_clusters[\"localDir0\"], label=\"strip x\", **config, linestyle=\"--\")\n        # ax.hist(strip_clusters[\"localDir1\"], label=\"strip y\", **config, linestyle=\"--\")\n        # ax.hist(strip_clusters[\"localDir2\"], label=\"strip z\", **config, linestyle=\"--\")\n        # ax.set_xlabel(\"Local directions\")\n        # plt.legend()\n        # plt.show()\n\n        # eta/phi from local/global directions of clusters\n        _, ax = create_figure(\"Pixel clusters\")\n        config = dict(bins=50, range=(-3.15, 3.15), histtype=\"step\", lw=2, alpha=0.8)\n        ax.hist(pixel_clusters[\"leta\"], label=r\"local $\\eta$\", **config)\n        ax.hist(pixel_clusters[\"lphi\"], label=r\"local $\\phi$\", **config)\n        ax.hist(pixel_clusters[\"glob_eta\"], label=r\"global $\\eta$\", **config, linestyle=\"--\")\n        ax.hist(pixel_clusters[\"glob_phi\"], label=r\"global $\\phi$\", **config, linestyle=\"--\")\n        ax.set_xlabel(\"Cluster Shapes\")\n        plt.legend()\n        plt.show()\n\n        # eta/phi from local/global directions of clusters\n        _, ax = create_figure(\"Strip clusters\")\n        config = dict(bins=50, range=(-3.15, 3.15), histtype=\"step\", lw=2, alpha=0.8)\n        ax.hist(strip_clusters[\"leta\"], label=r\"local $\\eta$\", **config)\n        ax.hist(strip_clusters[\"lphi\"], label=r\"local $\\phi$\", **config)\n        ax.hist(strip_clusters[\"glob_eta\"], label=r\"global $\\eta$\", **config, linestyle=\"--\")\n        ax.hist(strip_clusters[\"glob_phi\"], label=r\"global $\\phi$\", **config, linestyle=\"--\")\n        ax.set_xlabel(\"Cluster Shapes\")\n        plt.legend()\n        plt.show()\n\n        # phi_angle and eta_angle\n        _, ax = create_figure(\"Strip clusters\")\n        config = dict(bins=50, range=(0, 3.15), histtype=\"step\", lw=2, alpha=0.8)\n        ax.hist(pixel_clusters[\"phi_angle\"], label=r\"Pixel $\\phi$\", **config)\n        ax.hist(pixel_clusters[\"eta_angle\"], label=r\"Pixel $\\eta$\", **config)\n        ax.hist(strip_clusters[\"phi_angle\"], label=r\"Strip $\\phi$\", **config)\n        ax.hist(strip_clusters[\"eta_angle\"], label=r\"Strip $\\eta$\", **config)\n        ax.set_xlabel(\"Cluster Angles\")\n        plt.legend()\n        plt.show()\n\n    @classmethod\n    def apply_eta_dep_cuts(\n        cls,\n        track: pd.DataFrame,\n        eta_bins: tuple[float] = (-0.01, 2.0, 2.6, 4.0),\n        min_hits: tuple[int] = (9, 8, 7),\n        min_pT: tuple[float] = (900, 400, 400),  # MeV\n        max_oot: tuple[float] = (10, 10, 10),\n        chi2_ndof: tuple[float] = (7, 7, 7),\n    ) -&gt; pd.Series:\n        \"\"\"Apply eta dependent cuts.\n        The default cuts are taken the ATLAS ITk performance paper.\n\n        eta: eta of the track\n        pT: pT of the track\n        mot: measurements on track\n        oot: outliers on track\n        chi2_ndof: chi2/ndof of the track\n\n        Return:\n            pass_allcuts: boolean array indicating if the track passes all cuts\n        \"\"\"\n        required_features = [\"eta\", \"pt\", \"mot\", \"oot\", \"chi2_ndof\"]\n        assert all(\n            f in track.columns for f in required_features\n        ), f\"Track data does not contain all required features: {required_features}\"\n\n        # apply eta dependent cuts on number of hits\n        track = track.assign(abseta=track[\"eta\"].abs())\n\n        def apply_cuts(value: str, cut_list: list[float], cmp_opt: str = \"&gt;\"):\n            query = \"|\".join([\n                f\"((abseta &gt; {eta_bins[idx]}) &amp; (abseta &lt;= {eta_bins[idx + 1]}) &amp; ({value} {cmp_opt} {cut}))\"\n                for idx, cut in enumerate(cut_list)\n            ])\n            # print(query)\n            return track.eval(query)\n\n        num_hits_cuts = apply_cuts(\"mot\", min_hits, \"&lt;\")\n        pt_cuts = apply_cuts(\"pt\", min_pT, \"&lt;=\")\n        outlier_cuts = apply_cuts(\"oot\", max_oot, \"&gt;\")\n        chi2_cuts = apply_cuts(\"chi2ndo\", chi2_ndof, \"&gt;\")\n\n        num_failed_hits = track[num_hits_cuts].shape[0]\n        num_failed_pt = track[pt_cuts].shape[0]\n        num_failed_outliers = track[outlier_cuts].shape[0]\n        num_failed_chi2 = track[chi2_cuts].shape[0]\n        num_failed_all = track[num_hits_cuts | pt_cuts | outlier_cuts | chi2_cuts].shape[0]\n        print(\"Total number of tracks: \", track.shape[0])\n        print(\n            \"Number of tracks failed number of hits cut: \",\n            num_failed_hits,\n            f\"({num_failed_hits / track.shape[0]:.2%})\",\n        )\n        print(\n            \"Number of tracks failed pT cut: \",\n            num_failed_pt,\n            f\"({num_failed_pt / track.shape[0]:.2%})\",\n        )\n        print(\n            \"Number of tracks failed outlier cut: \",\n            num_failed_outliers,\n            f\"({num_failed_outliers / track.shape[0]:.2%})\",\n        )\n        print(\n            \"Number of tracks failed chi2 cut: \",\n            num_failed_chi2,\n            f\"({num_failed_chi2 / track.shape[0]:.2%})\",\n        )\n        print(\n            \"Number of tracks failed all cuts: \",\n            num_failed_all,\n            f\"({num_failed_all / track.shape[0]:.2%})\",\n        )\n\n        # number of hits vs |eta|\n        _, ax = create_figure()\n        ax.scatter(track.abseta, track.mot, alpha=0.5, s=10)\n\n        def add_cut_lines(ax, cut_list: list[float], color=\"red\"):\n            if len(eta_bins) &gt; 1:\n                for idx, cut in enumerate(cut_list):\n                    ax.plot([eta_bins[idx], eta_bins[idx + 1]], [cut, cut], color=color)\n                for idx in range(1, len(eta_bins) - 1):\n                    ax.plot(\n                        [eta_bins[idx], eta_bins[idx]],\n                        [cut_list[idx - 1], cut_list[idx]],\n                        color=color,\n                    )\n            else:\n                plt.axhline(cut_list[0], color=color)\n\n        add_cut_lines(ax, min_hits)\n        ax.set_xlabel(r\"$|\\eta|$\")\n        ax.set_ylabel(\"# of clusters\")\n        plt.show()\n\n        # pT vs |eta|\n        _, ax = create_figure()\n        ax.scatter(track.abseta, track.pt, alpha=0.5, s=10)\n        add_cut_lines(ax, min_pT)\n        ax.set_xlabel(r\"$|\\eta|$\")\n        ax.set_ylabel(\"pT [MeV]\")\n        ax.set_ylim(0, 5000)\n        plt.show()\n\n        pass_allcuts = not (num_hits_cuts | pt_cuts | outlier_cuts | chi2_cuts)\n        return pass_allcuts\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.analyze_track_data.TrackAnalyzer.study_cluster_features","title":"<code>study_cluster_features(evtid=0)</code>","text":"<p>Study the cluster features</p> Source code in <code>src/heptracktool/tools/analyze_track_data.py</code> <pre><code>def study_cluster_features(self, evtid: int = 0):\n    \"\"\"Study the cluster features\"\"\"\n    self.reader.read(evtid)\n    if self.reader.clusters is None:\n        print(f\"No cluster information found in {self.reader.name} for event {evtid}.\")\n\n    clusters = self.reader.clusters\n    print(\"Number of clusters: \", clusters.shape[0])\n    pixel_clusters = clusters[clusters[\"hardware\"] == \"PIXEL\"]\n    strip_clusters = clusters[clusters[\"hardware\"] == \"STRIP\"]\n    print(\"Number of pixel clusters: \", pixel_clusters.shape[0])\n    print(\"Number of strip clusters: \", strip_clusters.shape[0])\n\n    # number of pixels per cluster\n    _, ax = create_figure()\n    config = dict(bins=31, range=(-0.5, 30.5), histtype=\"step\", lw=2, alpha=0.8)\n    ax.hist(pixel_clusters[\"pixel_count\"], label=\"Pixel clusters\", **config)\n    ax.hist(strip_clusters[\"pixel_count\"], label=\"Strip clusters\", **config)\n    ax.set_xlabel(\"# of Pixels per cluster\")\n    plt.legend()\n    plt.show()\n\n    # number of charges per cluster\n    print(\"Charge information is not available for strip clusters\")\n    _, ax = create_figure()\n    config = dict(bins=51, range=(-0.5, 50.5), histtype=\"step\", lw=2)\n    ax.hist(pixel_clusters[\"charge_count\"], label=\"Pixel clusters\", **config)\n    ax.set_xlabel(\"# of Charges per cluster\")\n    add_mean_std(pixel_clusters[\"charge_count\"], 15, 15000, ax, dy=2500)\n    plt.legend()\n    plt.show()\n\n    # cluster position\n    _, ax = create_figure()\n    config = dict(bins=600, range=(-3000, 3000), histtype=\"step\", lw=2, alpha=0.8)\n    ax.hist(pixel_clusters[\"cluster_x\"], label=\"pixel x\", **config)\n    ax.hist(pixel_clusters[\"cluster_y\"], label=\"pixel y\", **config)\n    ax.hist(pixel_clusters[\"cluster_z\"], label=\"pixel z\", **config)\n    ax.hist(strip_clusters[\"cluster_x\"], label=\"strip x\", **config, linestyle=\"--\")\n    ax.hist(strip_clusters[\"cluster_y\"], label=\"strip y\", **config, linestyle=\"--\")\n    ax.hist(strip_clusters[\"cluster_z\"], label=\"strip z\", **config, linestyle=\"--\")\n    ax.set_xlabel(\"Cluster position [mm]\")\n    plt.legend()\n    plt.show()\n\n    # # local directions of clusters\n    # _, ax = create_figure()\n    # config = dict(bins=50, range=(0, 30.0), histtype=\"step\", lw=2, alpha=0.8)\n    # ax.hist(pixel_clusters[\"localDir0\"], label=\"pixel x\", **config)\n    # ax.hist(pixel_clusters[\"localDir1\"], label=\"pixel y\", **config)\n    # ax.hist(pixel_clusters[\"localDir2\"], label=\"pixel z\", **config)\n    # ax.hist(strip_clusters[\"localDir0\"], label=\"strip x\", **config, linestyle=\"--\")\n    # ax.hist(strip_clusters[\"localDir1\"], label=\"strip y\", **config, linestyle=\"--\")\n    # ax.hist(strip_clusters[\"localDir2\"], label=\"strip z\", **config, linestyle=\"--\")\n    # ax.set_xlabel(\"Local directions\")\n    # plt.legend()\n    # plt.show()\n\n    # eta/phi from local/global directions of clusters\n    _, ax = create_figure(\"Pixel clusters\")\n    config = dict(bins=50, range=(-3.15, 3.15), histtype=\"step\", lw=2, alpha=0.8)\n    ax.hist(pixel_clusters[\"leta\"], label=r\"local $\\eta$\", **config)\n    ax.hist(pixel_clusters[\"lphi\"], label=r\"local $\\phi$\", **config)\n    ax.hist(pixel_clusters[\"glob_eta\"], label=r\"global $\\eta$\", **config, linestyle=\"--\")\n    ax.hist(pixel_clusters[\"glob_phi\"], label=r\"global $\\phi$\", **config, linestyle=\"--\")\n    ax.set_xlabel(\"Cluster Shapes\")\n    plt.legend()\n    plt.show()\n\n    # eta/phi from local/global directions of clusters\n    _, ax = create_figure(\"Strip clusters\")\n    config = dict(bins=50, range=(-3.15, 3.15), histtype=\"step\", lw=2, alpha=0.8)\n    ax.hist(strip_clusters[\"leta\"], label=r\"local $\\eta$\", **config)\n    ax.hist(strip_clusters[\"lphi\"], label=r\"local $\\phi$\", **config)\n    ax.hist(strip_clusters[\"glob_eta\"], label=r\"global $\\eta$\", **config, linestyle=\"--\")\n    ax.hist(strip_clusters[\"glob_phi\"], label=r\"global $\\phi$\", **config, linestyle=\"--\")\n    ax.set_xlabel(\"Cluster Shapes\")\n    plt.legend()\n    plt.show()\n\n    # phi_angle and eta_angle\n    _, ax = create_figure(\"Strip clusters\")\n    config = dict(bins=50, range=(0, 3.15), histtype=\"step\", lw=2, alpha=0.8)\n    ax.hist(pixel_clusters[\"phi_angle\"], label=r\"Pixel $\\phi$\", **config)\n    ax.hist(pixel_clusters[\"eta_angle\"], label=r\"Pixel $\\eta$\", **config)\n    ax.hist(strip_clusters[\"phi_angle\"], label=r\"Strip $\\phi$\", **config)\n    ax.hist(strip_clusters[\"eta_angle\"], label=r\"Strip $\\eta$\", **config)\n    ax.set_xlabel(\"Cluster Angles\")\n    plt.legend()\n    plt.show()\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.analyze_track_data.TrackAnalyzer.apply_eta_dep_cuts","title":"<code>apply_eta_dep_cuts(track, eta_bins=(-0.01, 2.0, 2.6, 4.0), min_hits=(9, 8, 7), min_pT=(900, 400, 400), max_oot=(10, 10, 10), chi2_ndof=(7, 7, 7))</code>  <code>classmethod</code>","text":"<p>Apply eta dependent cuts. The default cuts are taken the ATLAS ITk performance paper.</p> <p>eta: eta of the track pT: pT of the track mot: measurements on track oot: outliers on track chi2_ndof: chi2/ndof of the track</p> Return <p>pass_allcuts: boolean array indicating if the track passes all cuts</p> Source code in <code>src/heptracktool/tools/analyze_track_data.py</code> <pre><code>@classmethod\ndef apply_eta_dep_cuts(\n    cls,\n    track: pd.DataFrame,\n    eta_bins: tuple[float] = (-0.01, 2.0, 2.6, 4.0),\n    min_hits: tuple[int] = (9, 8, 7),\n    min_pT: tuple[float] = (900, 400, 400),  # MeV\n    max_oot: tuple[float] = (10, 10, 10),\n    chi2_ndof: tuple[float] = (7, 7, 7),\n) -&gt; pd.Series:\n    \"\"\"Apply eta dependent cuts.\n    The default cuts are taken the ATLAS ITk performance paper.\n\n    eta: eta of the track\n    pT: pT of the track\n    mot: measurements on track\n    oot: outliers on track\n    chi2_ndof: chi2/ndof of the track\n\n    Return:\n        pass_allcuts: boolean array indicating if the track passes all cuts\n    \"\"\"\n    required_features = [\"eta\", \"pt\", \"mot\", \"oot\", \"chi2_ndof\"]\n    assert all(\n        f in track.columns for f in required_features\n    ), f\"Track data does not contain all required features: {required_features}\"\n\n    # apply eta dependent cuts on number of hits\n    track = track.assign(abseta=track[\"eta\"].abs())\n\n    def apply_cuts(value: str, cut_list: list[float], cmp_opt: str = \"&gt;\"):\n        query = \"|\".join([\n            f\"((abseta &gt; {eta_bins[idx]}) &amp; (abseta &lt;= {eta_bins[idx + 1]}) &amp; ({value} {cmp_opt} {cut}))\"\n            for idx, cut in enumerate(cut_list)\n        ])\n        # print(query)\n        return track.eval(query)\n\n    num_hits_cuts = apply_cuts(\"mot\", min_hits, \"&lt;\")\n    pt_cuts = apply_cuts(\"pt\", min_pT, \"&lt;=\")\n    outlier_cuts = apply_cuts(\"oot\", max_oot, \"&gt;\")\n    chi2_cuts = apply_cuts(\"chi2ndo\", chi2_ndof, \"&gt;\")\n\n    num_failed_hits = track[num_hits_cuts].shape[0]\n    num_failed_pt = track[pt_cuts].shape[0]\n    num_failed_outliers = track[outlier_cuts].shape[0]\n    num_failed_chi2 = track[chi2_cuts].shape[0]\n    num_failed_all = track[num_hits_cuts | pt_cuts | outlier_cuts | chi2_cuts].shape[0]\n    print(\"Total number of tracks: \", track.shape[0])\n    print(\n        \"Number of tracks failed number of hits cut: \",\n        num_failed_hits,\n        f\"({num_failed_hits / track.shape[0]:.2%})\",\n    )\n    print(\n        \"Number of tracks failed pT cut: \",\n        num_failed_pt,\n        f\"({num_failed_pt / track.shape[0]:.2%})\",\n    )\n    print(\n        \"Number of tracks failed outlier cut: \",\n        num_failed_outliers,\n        f\"({num_failed_outliers / track.shape[0]:.2%})\",\n    )\n    print(\n        \"Number of tracks failed chi2 cut: \",\n        num_failed_chi2,\n        f\"({num_failed_chi2 / track.shape[0]:.2%})\",\n    )\n    print(\n        \"Number of tracks failed all cuts: \",\n        num_failed_all,\n        f\"({num_failed_all / track.shape[0]:.2%})\",\n    )\n\n    # number of hits vs |eta|\n    _, ax = create_figure()\n    ax.scatter(track.abseta, track.mot, alpha=0.5, s=10)\n\n    def add_cut_lines(ax, cut_list: list[float], color=\"red\"):\n        if len(eta_bins) &gt; 1:\n            for idx, cut in enumerate(cut_list):\n                ax.plot([eta_bins[idx], eta_bins[idx + 1]], [cut, cut], color=color)\n            for idx in range(1, len(eta_bins) - 1):\n                ax.plot(\n                    [eta_bins[idx], eta_bins[idx]],\n                    [cut_list[idx - 1], cut_list[idx]],\n                    color=color,\n                )\n        else:\n            plt.axhline(cut_list[0], color=color)\n\n    add_cut_lines(ax, min_hits)\n    ax.set_xlabel(r\"$|\\eta|$\")\n    ax.set_ylabel(\"# of clusters\")\n    plt.show()\n\n    # pT vs |eta|\n    _, ax = create_figure()\n    ax.scatter(track.abseta, track.pt, alpha=0.5, s=10)\n    add_cut_lines(ax, min_pT)\n    ax.set_xlabel(r\"$|\\eta|$\")\n    ax.set_ylabel(\"pT [MeV]\")\n    ax.set_ylim(0, 5000)\n    plt.show()\n\n    pass_allcuts = not (num_hits_cuts | pt_cuts | outlier_cuts | chi2_cuts)\n    return pass_allcuts\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.compare_tracking_algs.TrackAlgComparator","title":"<code>TrackAlgComparator</code>","text":"Source code in <code>src/heptracktool/tools/compare_tracking_algs.py</code> <pre><code>class TrackAlgComparator:\n    def __init__(\n        self, reader, other_reader, min_reco_clusters=5, name=\"TrackAlgComparator\"\n    ) -&gt; None:\n        super().__init__()\n        self.reader = reader\n        self.other_reader = other_reader\n        self.min_reco_clusters = min_reco_clusters\n        self.name = name\n\n        # common tracks\n        self.common_track_indices: list[tuple[int, list[int], int]] = None\n        self.common_info: pd.DataFrame = None\n        self.common_track: pd.DataFrame = None\n        self.common_other_track: pd.DataFrame = None\n\n        # disjoint tracks\n        self.disjoint_track_indices: list[tuple[int, list[int]]] = None\n        self.disjoint_info: pd.DataFrame = None\n        self.disjoint_track: pd.DataFrame = None\n        self.disjoint_other_track: pd.DataFrame = None\n\n        # unmatched tracks\n        self.unmatched_tracks: list[tuple[int, list[int]]] = None\n\n        # optional to reverse the comparison in the run time.\n        self._reverse_comparison = False\n        self.redo_comparison = False\n\n    def readers(self):\n        return (\n            (self.reader, self.other_reader)\n            if not self.reverse_comparison\n            else (self.other_reader, self.reader)\n        )\n\n    @property\n    def reverse_comparison(self) -&gt; bool:\n        \"\"\"Return the reverse comparison flag.\"\"\"\n        return self._reverse_comparison\n\n    @reverse_comparison.setter\n    def reverse_comparison(self, do_reverse: bool = False) -&gt; None:\n        \"\"\"Set the reverse comparison flag.\"\"\"\n        if self._reverse_comparison != do_reverse:\n            # changing the comparison direction\n            # so we need to redo the comparison\n            self.redo_comparison = True\n            self._reverse_comparison = do_reverse\n\n    def compare_track_contents(self) -&gt; tuple[Any, Any, Any]:\n        \"\"\"Compares each track in the first track collection\n        with all tracks in the other track collection. Each track is labeled as\n        common (also means matched), disjoint, or unmatched.\n        common:\n          the contents of the track are exactly the same as\n          another track in the other collection (matched).\n        disjoint:\n          the contents of the track do not exist in any track in the other collection.\n        unmatched:\n          track do not match to any track in the other collection.\n\n        Returns\n        -------\n            common_tracks: list of tuples of (track_id, track, cluster ids, other_track_id)\n            unmatched_tracks: list of tuples of (track_id, cluster ids)\n            disjoint_tracks: list of tuples of (track_id, cluster ids)\n\n        Raises\n        ------\n            ValueError: If the track contents are empty.\n        \"\"\"\n        if not self.redo_comparison and self.common_info is not None:\n            return (\n                self.common_track_indices,\n                self.unmatched_tracks,\n                self.disjoint_track_indices,\n            )\n\n        track_reader, other_track_reader = self.readers()\n        min_num_clusters = self.min_reco_clusters\n\n        label, other_label = track_reader.name, other_track_reader.name\n        tracks, other_tracks = (\n            track_reader.clusters_on_track,\n            other_track_reader.clusters_on_track,\n        )\n        if tracks is None or other_tracks is None:\n            raise ValueError(\"Track contents are empty.\")\n\n        num_matched = 0\n        num_issubset = 0\n        num_other_issubset = 0\n        num_disjoints = 0\n\n        unmatched_tracks = []\n        disjoint_tracks = []\n        common_tracks = []\n\n        tot_tracks, tot_other_tracks = len(tracks), len(other_tracks)\n        print(\n            f\"{tot_tracks} {label} tracks compared to {tot_other_tracks} {other_label} tracks.\\n\"\n            f\"Require min_num_clusters = {min_num_clusters} only for {label} tracks.\"\n        )\n\n        tot_filtered_tracks = 0\n        for trkid, track in enumerate(tracks):\n            if len(track) &lt; min_num_clusters:\n                continue\n            tot_filtered_tracks += 1\n            found_a_match = False\n            all_disjoint = True\n            found_as_subset = False\n            found_other_as_subset = False\n            ckf_idx = -1\n\n            for idx, other_track in enumerate(other_tracks):\n                track_set = set(track)\n                other_track_set = set(other_track)\n                if not track_set.isdisjoint(other_track_set):\n                    all_disjoint = False\n                if track_set == other_track_set:\n                    found_a_match = True\n                    ckf_idx = idx\n                if track_set &lt; other_track_set:\n                    found_as_subset = True\n                if track_set &gt; other_track_set:\n                    found_other_as_subset = True\n\n            if found_a_match:\n                num_matched += 1\n                common_tracks.append((trkid, track, ckf_idx))\n            else:\n                unmatched_tracks.append((trkid, track))\n\n            if all_disjoint:\n                num_disjoints += 1\n                disjoint_tracks.append((trkid, track))\n            if found_as_subset:\n                num_issubset += 1\n            if found_other_as_subset:\n                num_other_issubset += 1\n\n        print(\n            f\"Total # of {label} tracks: {tot_tracks}. After filtering, \"\n            f\"# of {label} tracks: {tot_filtered_tracks} ({tot_filtered_tracks / tot_tracks:.3%})\"\n        )\n        print(\n            f\"Matched: {num_matched}, {tot_filtered_tracks}, {num_matched / tot_filtered_tracks:.4%}\"\n        )\n        print(\n            f\"{label} is a subset: {num_issubset}, {tot_filtered_tracks}, \"\n            f\"{num_issubset / tot_filtered_tracks:.4%}\"\n        )\n        print(\n            f\"{other_label} is a subset: {num_other_issubset}, {tot_filtered_tracks}, \"\n            f\"{num_other_issubset / tot_filtered_tracks:.4%}\"\n        )\n        print(\n            f\"Disjoint:  {num_disjoints}, {tot_filtered_tracks}, {num_disjoints / tot_filtered_tracks:.4%}\"\n        )\n\n        (\n            self.common_track_indices,\n            self.unmatched_tracks,\n            self.disjoint_track_indices,\n        ) = (common_tracks, unmatched_tracks, disjoint_tracks)\n\n        # if we have already done the comparison, set the redo flag to False\n        if self.redo_comparison:\n            self.redo_comparison = False\n\n        return (common_tracks, unmatched_tracks, disjoint_tracks)\n\n    def analyse_common_track(self) -&gt; pd.DataFrame:\n        \"\"\"Return a common track object.\n\n        Returns\n        -------\n            df_common: pd.DataFrame\n        \"\"\"\n        self.compare_track_contents()\n\n        common_tracks = self.common_track_indices\n        reader, other_reader = self.readers()\n\n        trk_id = np.array([x[0] for x in common_tracks])\n        other_trk_id = np.array([x[2] for x in common_tracks])\n        nclusters = np.array([len(x[1]) for x in common_tracks])\n        df_common = pd.DataFrame({\n            f\"{reader.name}_trkid\": trk_id,\n            f\"{other_reader.name}_trkid\": other_trk_id,\n            \"nclusters\": nclusters,\n        })\n        self.common_info = df_common\n\n        # `isin` does not preserve the order of the original array\n        # but the dataframe index is the same as trk_id.\n        self.common_track = reader.tracks.loc[trk_id]\n        self.other_common_track = other_reader.tracks.loc[other_trk_id]\n\n        return df_common\n\n    def plot_common_tracks(self) -&gt; tuple[np.array, np.array]:\n        \"\"\"Analyze the common tracks. Compare their chi2 and other metrics.\"\"\"\n        df = self.analyse_common_track()\n        reader, other_reader = self.readers()\n        label, other_label = reader.name, other_reader.name\n\n        num_common_tracks = len(df)\n\n        # number of clusters\n        plt.title(\"Common tracks\")\n        plt.hist(\n            df.nclusters.values,\n            bins=31,\n            range=(-0.5, 30.5),\n            label=f\"Total {num_common_tracks}\",\n            alpha=0.5,\n        )\n        plt.legend()\n        plt.xlabel(\"number of clusters\")\n        plt.show()\n\n        # chi2 / ndof\n        chi2_hist_config = {\n            \"bins\": 50,\n            \"range\": (0, 4),\n            \"alpha\": 0.5,\n            \"histtype\": \"step\",\n            \"lw\": 2,\n        }\n        chi2 = self.common_track.chi2.to_numpy() / self.common_track.nDoF.to_numpy()\n        other_chi2 = (\n            self.other_common_track.chi2.to_numpy() / self.other_common_track.nDoF.to_numpy()\n        )\n        plt.title(\"Common Tracks\")\n        plt.hist(chi2, **chi2_hist_config, label=label)\n        plt.hist(other_chi2, **chi2_hist_config, label=other_label)\n        plt.xlim(0, 4)\n        plt.xlabel(r\"$\\chi^2$/ndof\")\n        plt.legend()\n        plt.show()\n\n        # scatter plot for chi2 / ndof\n        plt.title(\"Common Tracks\")\n        config = {\"s\": 10, \"alpha\": 0.5}\n        plt.scatter(chi2, other_chi2, **config)\n        plt.plot([0, 4], [0, 4], color=\"red\", linestyle=\"--\")\n        plt.xlim(0, 4)\n        plt.ylim(0, 4)\n        plt.xlabel(rf\"{label} $\\chi^2$/ndof\")\n        plt.ylabel(rf\"{other_label} $\\chi^2$/ndof\")\n        plt.show()\n\n        # difference in chi2 / ndof\n        delta_chi2 = chi2 - other_chi2\n        plt.title(\"Common Tracks\")\n        bin_values, _, _ = plt.hist(delta_chi2, bins=50, range=(-2, 2), alpha=0.5)\n        max_bin_value, min_bin_value = np.max(bin_values), np.min(bin_values)\n        y_start = max_bin_value * 0.5\n        delta = (max_bin_value - min_bin_value) * 0.08\n        plt.text(-1.5, y_start, f\"Mean: {np.mean(delta_chi2):8.4f}\", fontsize=12)\n        plt.text(-1.5, y_start - delta, f\"Std:  {np.std(delta_chi2):8.4f}\", fontsize=12)\n        plt.xlabel(rf\"({label} - {other_label}) $\\chi^2$/ndof\")\n        plt.plot([0, 0], [0, max_bin_value], color=\"red\", linestyle=\"--\")\n        plt.show()\n\n        return chi2, other_chi2\n\n    def match_to_truth(self) -&gt; None:\n        \"\"\"Match a track to the truth track.\"\"\"\n        reader, other_reader = self.readers()\n        reader.match_to_truth()\n        other_reader.match_to_truth()\n\n    def plot_disjoint_tracks(self) -&gt; tuple[pd.DataFrame, pd.DataFrame]:\n        \"\"\"Analyze the disjoint tracks. We have to the comparison twice.\n        Once looping over the tracks in the first reader,\n        and once looping over the tracks in the second reader.\n        \"\"\"\n        reader, other_reader = self.readers()\n        self.match_to_truth()  # will be used to quanlify the disjoint tracks\n        label, other_label = reader.name, other_reader.name\n\n        # perform the comparison to find disjoint tracks\n        # for reader and other_reader\n        self.reverse_comparison = True\n        _, _, disjoint_other_tracks = self.compare_track_contents()\n\n        # reset the flag\n        self.reverse_comparison = False\n        _, _, disjoint_tracks = self.compare_track_contents()\n\n        # compare the two disjoint track lists\n        num_disjoints = len(disjoint_tracks)\n        num_other_disjoints = len(disjoint_other_tracks)\n\n        cluster_config = {\"bins\": 31, \"range\": (-0.5, 30.5), \"alpha\": 0.5}\n        plt.title(\"Disjoint tracks\")\n        plt.hist(\n            [len(x[1]) for x in disjoint_tracks],\n            **cluster_config,\n            label=f\"{label} {num_disjoints}\",\n        )\n        plt.hist(\n            [len(x[1]) for x in disjoint_other_tracks],\n            **cluster_config,\n            label=f\"{other_label} {num_other_disjoints}\",\n        )\n        plt.legend()\n        plt.xlabel(\"number of clusters\")\n        plt.show()\n\n        # good disjoint tracks\n        tracks_matched_to_truth = reader.tracks_matched_to_truth\n        disjoint_track_indices = np.array([x[0] for x in disjoint_tracks], dtype=int)\n        good_disjoints = tracks_matched_to_truth[\n            tracks_matched_to_truth.trkid.isin(disjoint_track_indices)\n        ]\n        num_good_disjoints = len(good_disjoints)\n\n        # other disjoint tracks\n        other_tracks_matched_to_truth = other_reader.tracks_matched_to_truth\n        disjoint_other_track_indices = np.array([x[0] for x in disjoint_other_tracks], dtype=int)\n        other_good_disjoints = other_tracks_matched_to_truth[\n            other_tracks_matched_to_truth.trkid.isin(disjoint_other_track_indices)\n        ]\n        num_other_good_disjoints = len(other_good_disjoints)\n\n        print(f\"Number of good disjoint {label} tracks: {num_good_disjoints} / {num_disjoints}\")\n        print(\n            f\"Number of good disjoint {other_label} tracks: {num_other_good_disjoints} / {num_other_disjoints}\"\n        )\n\n        # plot the number of clusters for the good disjoint tracks\n        good_disjoints_tot_hits = good_disjoints.reco_pixel_hits + good_disjoints.reco_sct_hits\n        other_good_disjoints_tot_hits = (\n            other_good_disjoints.reco_pixel_hits + other_good_disjoints.reco_sct_hits\n        )\n\n        plt.title(\"Good Disjoint Tracks\")\n        plt.hist(\n            good_disjoints_tot_hits,\n            **cluster_config,\n            label=f\"{label} {num_good_disjoints}/{num_disjoints}\",\n        )\n        plt.hist(\n            other_good_disjoints_tot_hits,\n            **cluster_config,\n            label=f\"{other_label} {num_other_good_disjoints}/{num_other_disjoints}\",\n        )\n        plt.legend()\n        plt.xlabel(\"Number of clusters\")\n        plt.show()\n\n        # plot particle PT of the matched good disjoint tracks\n        plt.title(\"Good Disjoint Tracks\")\n        particles = reader.particles\n\n        matched_particles = particles[\n            particles.particle_id.isin(good_disjoints.particle_id.values)\n        ]\n        other_matched_particles = particles[\n            particles.particle_id.isin(other_good_disjoints.particle_id.values)\n        ]\n\n        pt = matched_particles.pt\n        pt_other = other_matched_particles.pt\n        num_high_pt = len(pt[pt &gt; 1000])\n        num_high_pt_other = len(pt_other[pt_other &gt; 1000])\n\n        pt_config = dict(bins=50, range=(0, 5000), alpha=0.5)\n        plt.title(\"Good disjoint tracks\")\n        plt.hist(pt, label=f\"{label} {len(pt)}\", **pt_config)\n        plt.text(2000, 40, f\"{label} pT &gt; 1 GeV: {num_high_pt:5}\", fontsize=12)\n        plt.text(2000, 30, f\"{other_label} pT &gt; 1 GeV: {num_high_pt_other:5}\", fontsize=12)\n        plt.hist(pt_other, label=f\"CKF {len(pt_other)}\", **pt_config)\n        plt.legend()\n        plt.xlabel(\"particle pT [MeV]\")\n        plt.show()\n\n        merged = matched_particles.merge(good_disjoints, on=\"particle_id\")\n        merged_other = other_matched_particles.merge(other_good_disjoints, on=\"particle_id\")\n        plt.title(\"Good Disjoint Tracks\")\n        config = dict(s=10.0, alpha=0.5)\n        plt.scatter(\n            merged.pt,\n            merged.reco_pixel_hits + merged.reco_sct_hits,\n            label=f\"{label}\",\n            **config,\n        )\n        plt.scatter(\n            merged_other.pt,\n            merged_other.reco_pixel_hits + merged_other.reco_sct_hits,\n            label=f\"{other_label}\",\n            **config,\n        )\n        plt.xlim(0, 5000)\n        plt.ylim(0, 30)\n        plt.xlabel(\"particle pT [MeV]\")\n        plt.ylabel(\"number of clusters\")\n        plt.legend()\n        plt.show()\n\n        return (\n            disjoint_other_tracks,\n            disjoint_other_tracks,\n            good_disjoints,\n            other_good_disjoints,\n            matched_particles,\n            other_matched_particles,\n        )\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.compare_tracking_algs.TrackAlgComparator.compare_track_contents","title":"<code>compare_track_contents()</code>","text":"<p>Compares each track in the first track collection with all tracks in the other track collection. Each track is labeled as common (also means matched), disjoint, or unmatched. common:   the contents of the track are exactly the same as   another track in the other collection (matched). disjoint:   the contents of the track do not exist in any track in the other collection. unmatched:   track do not match to any track in the other collection.</p>"},{"location":"api/heptracktool/tools/#heptracktool.tools.compare_tracking_algs.TrackAlgComparator.compare_track_contents--returns","title":"Returns","text":"<pre><code>common_tracks: list of tuples of (track_id, track, cluster ids, other_track_id)\nunmatched_tracks: list of tuples of (track_id, cluster ids)\ndisjoint_tracks: list of tuples of (track_id, cluster ids)\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.compare_tracking_algs.TrackAlgComparator.compare_track_contents--raises","title":"Raises","text":"<pre><code>ValueError: If the track contents are empty.\n</code></pre> Source code in <code>src/heptracktool/tools/compare_tracking_algs.py</code> <pre><code>def compare_track_contents(self) -&gt; tuple[Any, Any, Any]:\n    \"\"\"Compares each track in the first track collection\n    with all tracks in the other track collection. Each track is labeled as\n    common (also means matched), disjoint, or unmatched.\n    common:\n      the contents of the track are exactly the same as\n      another track in the other collection (matched).\n    disjoint:\n      the contents of the track do not exist in any track in the other collection.\n    unmatched:\n      track do not match to any track in the other collection.\n\n    Returns\n    -------\n        common_tracks: list of tuples of (track_id, track, cluster ids, other_track_id)\n        unmatched_tracks: list of tuples of (track_id, cluster ids)\n        disjoint_tracks: list of tuples of (track_id, cluster ids)\n\n    Raises\n    ------\n        ValueError: If the track contents are empty.\n    \"\"\"\n    if not self.redo_comparison and self.common_info is not None:\n        return (\n            self.common_track_indices,\n            self.unmatched_tracks,\n            self.disjoint_track_indices,\n        )\n\n    track_reader, other_track_reader = self.readers()\n    min_num_clusters = self.min_reco_clusters\n\n    label, other_label = track_reader.name, other_track_reader.name\n    tracks, other_tracks = (\n        track_reader.clusters_on_track,\n        other_track_reader.clusters_on_track,\n    )\n    if tracks is None or other_tracks is None:\n        raise ValueError(\"Track contents are empty.\")\n\n    num_matched = 0\n    num_issubset = 0\n    num_other_issubset = 0\n    num_disjoints = 0\n\n    unmatched_tracks = []\n    disjoint_tracks = []\n    common_tracks = []\n\n    tot_tracks, tot_other_tracks = len(tracks), len(other_tracks)\n    print(\n        f\"{tot_tracks} {label} tracks compared to {tot_other_tracks} {other_label} tracks.\\n\"\n        f\"Require min_num_clusters = {min_num_clusters} only for {label} tracks.\"\n    )\n\n    tot_filtered_tracks = 0\n    for trkid, track in enumerate(tracks):\n        if len(track) &lt; min_num_clusters:\n            continue\n        tot_filtered_tracks += 1\n        found_a_match = False\n        all_disjoint = True\n        found_as_subset = False\n        found_other_as_subset = False\n        ckf_idx = -1\n\n        for idx, other_track in enumerate(other_tracks):\n            track_set = set(track)\n            other_track_set = set(other_track)\n            if not track_set.isdisjoint(other_track_set):\n                all_disjoint = False\n            if track_set == other_track_set:\n                found_a_match = True\n                ckf_idx = idx\n            if track_set &lt; other_track_set:\n                found_as_subset = True\n            if track_set &gt; other_track_set:\n                found_other_as_subset = True\n\n        if found_a_match:\n            num_matched += 1\n            common_tracks.append((trkid, track, ckf_idx))\n        else:\n            unmatched_tracks.append((trkid, track))\n\n        if all_disjoint:\n            num_disjoints += 1\n            disjoint_tracks.append((trkid, track))\n        if found_as_subset:\n            num_issubset += 1\n        if found_other_as_subset:\n            num_other_issubset += 1\n\n    print(\n        f\"Total # of {label} tracks: {tot_tracks}. After filtering, \"\n        f\"# of {label} tracks: {tot_filtered_tracks} ({tot_filtered_tracks / tot_tracks:.3%})\"\n    )\n    print(\n        f\"Matched: {num_matched}, {tot_filtered_tracks}, {num_matched / tot_filtered_tracks:.4%}\"\n    )\n    print(\n        f\"{label} is a subset: {num_issubset}, {tot_filtered_tracks}, \"\n        f\"{num_issubset / tot_filtered_tracks:.4%}\"\n    )\n    print(\n        f\"{other_label} is a subset: {num_other_issubset}, {tot_filtered_tracks}, \"\n        f\"{num_other_issubset / tot_filtered_tracks:.4%}\"\n    )\n    print(\n        f\"Disjoint:  {num_disjoints}, {tot_filtered_tracks}, {num_disjoints / tot_filtered_tracks:.4%}\"\n    )\n\n    (\n        self.common_track_indices,\n        self.unmatched_tracks,\n        self.disjoint_track_indices,\n    ) = (common_tracks, unmatched_tracks, disjoint_tracks)\n\n    # if we have already done the comparison, set the redo flag to False\n    if self.redo_comparison:\n        self.redo_comparison = False\n\n    return (common_tracks, unmatched_tracks, disjoint_tracks)\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.compare_tracking_algs.TrackAlgComparator.analyse_common_track","title":"<code>analyse_common_track()</code>","text":"<p>Return a common track object.</p>"},{"location":"api/heptracktool/tools/#heptracktool.tools.compare_tracking_algs.TrackAlgComparator.analyse_common_track--returns","title":"Returns","text":"<pre><code>df_common: pd.DataFrame\n</code></pre> Source code in <code>src/heptracktool/tools/compare_tracking_algs.py</code> <pre><code>def analyse_common_track(self) -&gt; pd.DataFrame:\n    \"\"\"Return a common track object.\n\n    Returns\n    -------\n        df_common: pd.DataFrame\n    \"\"\"\n    self.compare_track_contents()\n\n    common_tracks = self.common_track_indices\n    reader, other_reader = self.readers()\n\n    trk_id = np.array([x[0] for x in common_tracks])\n    other_trk_id = np.array([x[2] for x in common_tracks])\n    nclusters = np.array([len(x[1]) for x in common_tracks])\n    df_common = pd.DataFrame({\n        f\"{reader.name}_trkid\": trk_id,\n        f\"{other_reader.name}_trkid\": other_trk_id,\n        \"nclusters\": nclusters,\n    })\n    self.common_info = df_common\n\n    # `isin` does not preserve the order of the original array\n    # but the dataframe index is the same as trk_id.\n    self.common_track = reader.tracks.loc[trk_id]\n    self.other_common_track = other_reader.tracks.loc[other_trk_id]\n\n    return df_common\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.compare_tracking_algs.TrackAlgComparator.plot_common_tracks","title":"<code>plot_common_tracks()</code>","text":"<p>Analyze the common tracks. Compare their chi2 and other metrics.</p> Source code in <code>src/heptracktool/tools/compare_tracking_algs.py</code> <pre><code>def plot_common_tracks(self) -&gt; tuple[np.array, np.array]:\n    \"\"\"Analyze the common tracks. Compare their chi2 and other metrics.\"\"\"\n    df = self.analyse_common_track()\n    reader, other_reader = self.readers()\n    label, other_label = reader.name, other_reader.name\n\n    num_common_tracks = len(df)\n\n    # number of clusters\n    plt.title(\"Common tracks\")\n    plt.hist(\n        df.nclusters.values,\n        bins=31,\n        range=(-0.5, 30.5),\n        label=f\"Total {num_common_tracks}\",\n        alpha=0.5,\n    )\n    plt.legend()\n    plt.xlabel(\"number of clusters\")\n    plt.show()\n\n    # chi2 / ndof\n    chi2_hist_config = {\n        \"bins\": 50,\n        \"range\": (0, 4),\n        \"alpha\": 0.5,\n        \"histtype\": \"step\",\n        \"lw\": 2,\n    }\n    chi2 = self.common_track.chi2.to_numpy() / self.common_track.nDoF.to_numpy()\n    other_chi2 = (\n        self.other_common_track.chi2.to_numpy() / self.other_common_track.nDoF.to_numpy()\n    )\n    plt.title(\"Common Tracks\")\n    plt.hist(chi2, **chi2_hist_config, label=label)\n    plt.hist(other_chi2, **chi2_hist_config, label=other_label)\n    plt.xlim(0, 4)\n    plt.xlabel(r\"$\\chi^2$/ndof\")\n    plt.legend()\n    plt.show()\n\n    # scatter plot for chi2 / ndof\n    plt.title(\"Common Tracks\")\n    config = {\"s\": 10, \"alpha\": 0.5}\n    plt.scatter(chi2, other_chi2, **config)\n    plt.plot([0, 4], [0, 4], color=\"red\", linestyle=\"--\")\n    plt.xlim(0, 4)\n    plt.ylim(0, 4)\n    plt.xlabel(rf\"{label} $\\chi^2$/ndof\")\n    plt.ylabel(rf\"{other_label} $\\chi^2$/ndof\")\n    plt.show()\n\n    # difference in chi2 / ndof\n    delta_chi2 = chi2 - other_chi2\n    plt.title(\"Common Tracks\")\n    bin_values, _, _ = plt.hist(delta_chi2, bins=50, range=(-2, 2), alpha=0.5)\n    max_bin_value, min_bin_value = np.max(bin_values), np.min(bin_values)\n    y_start = max_bin_value * 0.5\n    delta = (max_bin_value - min_bin_value) * 0.08\n    plt.text(-1.5, y_start, f\"Mean: {np.mean(delta_chi2):8.4f}\", fontsize=12)\n    plt.text(-1.5, y_start - delta, f\"Std:  {np.std(delta_chi2):8.4f}\", fontsize=12)\n    plt.xlabel(rf\"({label} - {other_label}) $\\chi^2$/ndof\")\n    plt.plot([0, 0], [0, max_bin_value], color=\"red\", linestyle=\"--\")\n    plt.show()\n\n    return chi2, other_chi2\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.compare_tracking_algs.TrackAlgComparator.plot_disjoint_tracks","title":"<code>plot_disjoint_tracks()</code>","text":"<p>Analyze the disjoint tracks. We have to the comparison twice. Once looping over the tracks in the first reader, and once looping over the tracks in the second reader.</p> Source code in <code>src/heptracktool/tools/compare_tracking_algs.py</code> <pre><code>def plot_disjoint_tracks(self) -&gt; tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"Analyze the disjoint tracks. We have to the comparison twice.\n    Once looping over the tracks in the first reader,\n    and once looping over the tracks in the second reader.\n    \"\"\"\n    reader, other_reader = self.readers()\n    self.match_to_truth()  # will be used to quanlify the disjoint tracks\n    label, other_label = reader.name, other_reader.name\n\n    # perform the comparison to find disjoint tracks\n    # for reader and other_reader\n    self.reverse_comparison = True\n    _, _, disjoint_other_tracks = self.compare_track_contents()\n\n    # reset the flag\n    self.reverse_comparison = False\n    _, _, disjoint_tracks = self.compare_track_contents()\n\n    # compare the two disjoint track lists\n    num_disjoints = len(disjoint_tracks)\n    num_other_disjoints = len(disjoint_other_tracks)\n\n    cluster_config = {\"bins\": 31, \"range\": (-0.5, 30.5), \"alpha\": 0.5}\n    plt.title(\"Disjoint tracks\")\n    plt.hist(\n        [len(x[1]) for x in disjoint_tracks],\n        **cluster_config,\n        label=f\"{label} {num_disjoints}\",\n    )\n    plt.hist(\n        [len(x[1]) for x in disjoint_other_tracks],\n        **cluster_config,\n        label=f\"{other_label} {num_other_disjoints}\",\n    )\n    plt.legend()\n    plt.xlabel(\"number of clusters\")\n    plt.show()\n\n    # good disjoint tracks\n    tracks_matched_to_truth = reader.tracks_matched_to_truth\n    disjoint_track_indices = np.array([x[0] for x in disjoint_tracks], dtype=int)\n    good_disjoints = tracks_matched_to_truth[\n        tracks_matched_to_truth.trkid.isin(disjoint_track_indices)\n    ]\n    num_good_disjoints = len(good_disjoints)\n\n    # other disjoint tracks\n    other_tracks_matched_to_truth = other_reader.tracks_matched_to_truth\n    disjoint_other_track_indices = np.array([x[0] for x in disjoint_other_tracks], dtype=int)\n    other_good_disjoints = other_tracks_matched_to_truth[\n        other_tracks_matched_to_truth.trkid.isin(disjoint_other_track_indices)\n    ]\n    num_other_good_disjoints = len(other_good_disjoints)\n\n    print(f\"Number of good disjoint {label} tracks: {num_good_disjoints} / {num_disjoints}\")\n    print(\n        f\"Number of good disjoint {other_label} tracks: {num_other_good_disjoints} / {num_other_disjoints}\"\n    )\n\n    # plot the number of clusters for the good disjoint tracks\n    good_disjoints_tot_hits = good_disjoints.reco_pixel_hits + good_disjoints.reco_sct_hits\n    other_good_disjoints_tot_hits = (\n        other_good_disjoints.reco_pixel_hits + other_good_disjoints.reco_sct_hits\n    )\n\n    plt.title(\"Good Disjoint Tracks\")\n    plt.hist(\n        good_disjoints_tot_hits,\n        **cluster_config,\n        label=f\"{label} {num_good_disjoints}/{num_disjoints}\",\n    )\n    plt.hist(\n        other_good_disjoints_tot_hits,\n        **cluster_config,\n        label=f\"{other_label} {num_other_good_disjoints}/{num_other_disjoints}\",\n    )\n    plt.legend()\n    plt.xlabel(\"Number of clusters\")\n    plt.show()\n\n    # plot particle PT of the matched good disjoint tracks\n    plt.title(\"Good Disjoint Tracks\")\n    particles = reader.particles\n\n    matched_particles = particles[\n        particles.particle_id.isin(good_disjoints.particle_id.values)\n    ]\n    other_matched_particles = particles[\n        particles.particle_id.isin(other_good_disjoints.particle_id.values)\n    ]\n\n    pt = matched_particles.pt\n    pt_other = other_matched_particles.pt\n    num_high_pt = len(pt[pt &gt; 1000])\n    num_high_pt_other = len(pt_other[pt_other &gt; 1000])\n\n    pt_config = dict(bins=50, range=(0, 5000), alpha=0.5)\n    plt.title(\"Good disjoint tracks\")\n    plt.hist(pt, label=f\"{label} {len(pt)}\", **pt_config)\n    plt.text(2000, 40, f\"{label} pT &gt; 1 GeV: {num_high_pt:5}\", fontsize=12)\n    plt.text(2000, 30, f\"{other_label} pT &gt; 1 GeV: {num_high_pt_other:5}\", fontsize=12)\n    plt.hist(pt_other, label=f\"CKF {len(pt_other)}\", **pt_config)\n    plt.legend()\n    plt.xlabel(\"particle pT [MeV]\")\n    plt.show()\n\n    merged = matched_particles.merge(good_disjoints, on=\"particle_id\")\n    merged_other = other_matched_particles.merge(other_good_disjoints, on=\"particle_id\")\n    plt.title(\"Good Disjoint Tracks\")\n    config = dict(s=10.0, alpha=0.5)\n    plt.scatter(\n        merged.pt,\n        merged.reco_pixel_hits + merged.reco_sct_hits,\n        label=f\"{label}\",\n        **config,\n    )\n    plt.scatter(\n        merged_other.pt,\n        merged_other.reco_pixel_hits + merged_other.reco_sct_hits,\n        label=f\"{other_label}\",\n        **config,\n    )\n    plt.xlim(0, 5000)\n    plt.ylim(0, 30)\n    plt.xlabel(\"particle pT [MeV]\")\n    plt.ylabel(\"number of clusters\")\n    plt.legend()\n    plt.show()\n\n    return (\n        disjoint_other_tracks,\n        disjoint_other_tracks,\n        good_disjoints,\n        other_good_disjoints,\n        matched_particles,\n        other_matched_particles,\n    )\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.edge_perf.EdgePerformance","title":"<code>EdgePerformance</code>","text":"Source code in <code>src/heptracktool/tools/edge_perf.py</code> <pre><code>class EdgePerformance:\n    def __init__(self, reader: TrackGraphDataReader, name=\"EdgePerformance\"):\n        self.reader = reader\n        self.name = name\n\n    def eval(self, edge_index: torch.Tensor, *args: Any, **kwds: Any) -&gt; Any:\n        \"\"\"Evaluate the per-edge performance\"\"\"\n\n        true_edges = self.reader.data[\"track_edges\"]\n        # get *undirected* graph\n        true_edges = torch.cat([true_edges, true_edges.flip(0)], dim=-1)\n\n        num_true_edges = true_edges.shape[1]\n\n        truth_labels = graph_intersection(edge_index, true_edges)\n\n        # per-edge efficiency\n        num_true_reco_edges = truth_labels.sum().item()\n        per_edge_efficiency = num_true_reco_edges / num_true_edges\n        logger.info(\n            f\"True Reco Edges {num_true_reco_edges:,}, True Edges {num_true_edges:,}, Per-edge efficiency: {per_edge_efficiency:.3%}\"\n        )\n\n        # per-edge purity\n        num_true_edges, num_reco_edges = true_edges.shape[1], edge_index.shape[1]\n        per_edge_purity = num_true_edges / num_reco_edges\n        logger.info(\n            f\"True Edges {num_true_edges:,}, Reco Edges {num_reco_edges:,}, Per-edge purity: {per_edge_purity:.3%}\"\n        )\n\n        # look at only the edges from nodes of interests.\n        masks = self.reader.get_edge_masks()\n        # undirected graph, so double the masks\n        masks = torch.cat([masks, masks], dim=-1)\n        # use the sender of the edge to quanlify the edge\n\n        masked_true_edges = true_edges[:, masks]\n        num_masked_true_edges = masked_true_edges.shape[1]\n        masked_truth_labels = graph_intersection(edge_index, masked_true_edges)\n        num_masked_true_reco_edges = masked_truth_labels.sum().item()\n        per_masked_edge_efficiency = num_masked_true_reco_edges / num_masked_true_edges\n        frac_masked_true_reco_edges = num_masked_true_edges / num_true_edges\n        logger.info(\n            f\"Only {frac_masked_true_reco_edges:.2%} of true edges are of interests (signal)\"\n        )\n        logger.info(\n            f\"True Reco Signal Edges {num_masked_true_reco_edges:,}, \"\n            f\"True Signal Edges {num_masked_true_edges:,}, \"\n            f\"Per-edge signal efficiency: {per_masked_edge_efficiency:.3%}\"\n        )\n\n        return (\n            truth_labels,\n            true_edges,\n            per_edge_efficiency,\n            per_edge_purity,\n            per_masked_edge_efficiency,\n        )\n\n    def eval_edge_scores(\n        self,\n        edge_score: Union[torch.Tensor, np.ndarray],\n        truth_labels: Union[torch.Tensor, np.ndarray],\n        edge_weights: Optional[torch.Tensor] = None,\n        edge_weight_cuts: float = 0,\n        outname: Optional[str] = None,\n    ):\n        \"\"\"Evaluate the per-edge performance given the edge scores.\n        If edge_weights is not None, only plot the edges with weights &gt; edge_weight_cuts.\n        Edge weights are used mostly to remove edges that are true but not of interests (non-signal edges).\n        \"\"\"\n        if isinstance(edge_score, torch.Tensor):\n            edge_score = edge_score.detach().cpu().numpy()\n        if isinstance(truth_labels, torch.Tensor):\n            truth_labels = truth_labels.detach().cpu().numpy()\n\n        results = plot_metrics(edge_score, truth_labels, outname=outname)\n        if edge_weights is not None:\n            target_score, target_truth = (\n                edge_score[edge_weights &gt; edge_weight_cuts],\n                truth_labels[edge_weights &gt; edge_weight_cuts],\n            )\n            target_results = plot_metrics(target_score, target_truth, outname=outname + \"-target\")\n            return results, target_results\n        return results\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.edge_perf.EdgePerformance.eval","title":"<code>eval(edge_index, *args, **kwds)</code>","text":"<p>Evaluate the per-edge performance</p> Source code in <code>src/heptracktool/tools/edge_perf.py</code> <pre><code>def eval(self, edge_index: torch.Tensor, *args: Any, **kwds: Any) -&gt; Any:\n    \"\"\"Evaluate the per-edge performance\"\"\"\n\n    true_edges = self.reader.data[\"track_edges\"]\n    # get *undirected* graph\n    true_edges = torch.cat([true_edges, true_edges.flip(0)], dim=-1)\n\n    num_true_edges = true_edges.shape[1]\n\n    truth_labels = graph_intersection(edge_index, true_edges)\n\n    # per-edge efficiency\n    num_true_reco_edges = truth_labels.sum().item()\n    per_edge_efficiency = num_true_reco_edges / num_true_edges\n    logger.info(\n        f\"True Reco Edges {num_true_reco_edges:,}, True Edges {num_true_edges:,}, Per-edge efficiency: {per_edge_efficiency:.3%}\"\n    )\n\n    # per-edge purity\n    num_true_edges, num_reco_edges = true_edges.shape[1], edge_index.shape[1]\n    per_edge_purity = num_true_edges / num_reco_edges\n    logger.info(\n        f\"True Edges {num_true_edges:,}, Reco Edges {num_reco_edges:,}, Per-edge purity: {per_edge_purity:.3%}\"\n    )\n\n    # look at only the edges from nodes of interests.\n    masks = self.reader.get_edge_masks()\n    # undirected graph, so double the masks\n    masks = torch.cat([masks, masks], dim=-1)\n    # use the sender of the edge to quanlify the edge\n\n    masked_true_edges = true_edges[:, masks]\n    num_masked_true_edges = masked_true_edges.shape[1]\n    masked_truth_labels = graph_intersection(edge_index, masked_true_edges)\n    num_masked_true_reco_edges = masked_truth_labels.sum().item()\n    per_masked_edge_efficiency = num_masked_true_reco_edges / num_masked_true_edges\n    frac_masked_true_reco_edges = num_masked_true_edges / num_true_edges\n    logger.info(\n        f\"Only {frac_masked_true_reco_edges:.2%} of true edges are of interests (signal)\"\n    )\n    logger.info(\n        f\"True Reco Signal Edges {num_masked_true_reco_edges:,}, \"\n        f\"True Signal Edges {num_masked_true_edges:,}, \"\n        f\"Per-edge signal efficiency: {per_masked_edge_efficiency:.3%}\"\n    )\n\n    return (\n        truth_labels,\n        true_edges,\n        per_edge_efficiency,\n        per_edge_purity,\n        per_masked_edge_efficiency,\n    )\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.edge_perf.EdgePerformance.eval_edge_scores","title":"<code>eval_edge_scores(edge_score, truth_labels, edge_weights=None, edge_weight_cuts=0, outname=None)</code>","text":"<p>Evaluate the per-edge performance given the edge scores. If edge_weights is not None, only plot the edges with weights &gt; edge_weight_cuts. Edge weights are used mostly to remove edges that are true but not of interests (non-signal edges).</p> Source code in <code>src/heptracktool/tools/edge_perf.py</code> <pre><code>def eval_edge_scores(\n    self,\n    edge_score: Union[torch.Tensor, np.ndarray],\n    truth_labels: Union[torch.Tensor, np.ndarray],\n    edge_weights: Optional[torch.Tensor] = None,\n    edge_weight_cuts: float = 0,\n    outname: Optional[str] = None,\n):\n    \"\"\"Evaluate the per-edge performance given the edge scores.\n    If edge_weights is not None, only plot the edges with weights &gt; edge_weight_cuts.\n    Edge weights are used mostly to remove edges that are true but not of interests (non-signal edges).\n    \"\"\"\n    if isinstance(edge_score, torch.Tensor):\n        edge_score = edge_score.detach().cpu().numpy()\n    if isinstance(truth_labels, torch.Tensor):\n        truth_labels = truth_labels.detach().cpu().numpy()\n\n    results = plot_metrics(edge_score, truth_labels, outname=outname)\n    if edge_weights is not None:\n        target_score, target_truth = (\n            edge_score[edge_weights &gt; edge_weight_cuts],\n            truth_labels[edge_weights &gt; edge_weight_cuts],\n        )\n        target_results = plot_metrics(target_score, target_truth, outname=outname + \"-target\")\n        return results, target_results\n    return results\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.model_inference.ExaTrkxInference","title":"<code>ExaTrkxInference</code>","text":"Source code in <code>src/heptracktool/tools/model_inference.py</code> <pre><code>class ExaTrkxInference:\n    def __init__(\n        self,\n        config_fname: str,\n        data_path: str,\n        device: str = \"cpu\",\n        name=\"ExaTrkxInference\",\n    ) -&gt; None:\n        self.name = name\n        self.device = device\n\n        with Path(config_fname).open() as f:\n            config = yaml.load(f, Loader=yaml.FullLoader)\n\n        self.config = config\n        self.process = psutil.Process()\n        self.system_data = []\n\n        self.data_reader = TrackGraphDataReader(data_path, name=self.name + \"DataReader\")\n        self.edge_perf = EdgePerformance(self.data_reader)\n\n        e_config = config[\"embedding\"]\n        self.embedding_model = torch.jit.load(e_config[\"model_path\"], map_location=self.device)\n        self.embedding_model.eval()\n        self.embedding_model.hparams = e_config\n\n        f_config = config[\"filtering\"]\n        self.filtering_model = torch.jit.load(f_config[\"model_path\"], map_location=self.device)\n        self.filtering_model.eval()\n        self.filtering_model.hparams = f_config\n\n        g_config = config.get(\"gnn\", None)\n        self.gnn_model = None\n        if g_config is not None:\n            self.gnn_model = torch.jit.load(g_config[\"model_path\"], map_location=self.device)\n            self.gnn_model.eval()\n            self.gnn_model.hparams = g_config\n\n    def _get_system_info(self):\n        # return memory usage in MB\n        # return cpu time in seconds\n        results = {}\n        process = self.process\n        with process.oneshot():\n            results[\"memory\"] = int(process.memory_full_info().uss / 1024**2)\n            results[\"cpu_time\"] = int(process.cpu_times().system)\n            results[\"datetime\"] = datetime.datetime.now()\n        return results\n\n    def _add_system_data(self, tag_name: str = \"start\"):\n        results = self._get_system_info()\n        results[\"tag\"] = tag_name\n        self.system_data.append(results)\n\n    def _print_memory_usage(self, tag_name: str):\n        print(\n            \"{} {}, CPU memory usage: {:,} MB\".format(\n                datetime.datetime.now().strftime(\"%H:%M:%S\"),\n                tag_name,\n                self._get_system_info()[\"memory\"],\n            )\n        )\n\n    def __call__(\n        self, evtid, filter_cut: float = 0.57, save_output: bool = False, *args, **kwargs\n    ):\n        self._print_memory_usage(\"Start\")\n\n        _ = self.data_reader.read(evtid)\n        self._print_memory_usage(\"After reading data\")\n        # embedding\n        node_features = self.embedding_model.hparams[\"node_features\"]\n        node_scales = self.embedding_model.hparams[\"node_scales\"]\n        features = self.data_reader.get_node_features(node_features, node_scales)\n        with torch.no_grad():\n            embedding = self.embedding_model.forward(features).detach()\n        self._print_memory_usage(\"After embedding\")\n\n        # FRNN\n        r_max = self.embedding_model.hparams[\"r_infer\"]\n        k_max = self.embedding_model.hparams[\"knn_infer\"]\n        knn_backend = self.embedding_model.hparams[\"knn_backend\"]\n        edge_index = build_edges(embedding, r_max=r_max, k_max=k_max, backend=knn_backend)\n        self._print_memory_usage(\"After FRNN\")\n        # edge-level performance\n        (\n            truth_labels,\n            true_edges,\n            per_edge_efficiency,\n            per_edge_purity,\n        ) = self.edge_perf.eval(edge_index)\n        self._print_memory_usage(\"After Edge Evaluation\")\n\n        # fetching filtering node features\n        node_features = self.filtering_model.hparams[\"node_features\"]\n        node_scales = self.filtering_model.hparams[\"node_scales\"]\n        features = self.data_reader.get_node_features(node_features, node_scales)\n        self._print_memory_usage(\"After Retrieving Filtering Node features\")\n\n        # get the senders and recievers\n        batch_size = self.filtering_model.hparams[\"batch_size\"]\n        senders, receivers = features[edge_index[0]], features[edge_index[1]]\n        self._print_memory_usage(\"After Splitting Node features\")\n\n        # filtering inference\n        filter_edge_scores = batched_inference(\n            self.filtering_model, senders, receivers, batch_size=batch_size\n        )\n        self._print_memory_usage(\"After Filtering\")\n        # apply sigmoid\n        filter_edge_scores = torch.sigmoid(filter_edge_scores)\n\n        # weights = self.data_reader.data.weights if \"weights\" in self.data_reader.data else None\n        # evaluate the edge scores\n        filter_perf = self.edge_perf.eval_edge_scores(\n            filter_edge_scores,\n            truth_labels,\n            outname=f\"perf_filtering_evt{evtid}\",\n        )\n\n        # obtain a threshold that gives 99% efficiency\n        # threshold = filter_perf[-1]\n        threshold = filter_cut\n        filtering_selections = filter_edge_scores &gt; threshold\n        edge_index = edge_index[:, filtering_selections]\n        # update the truth labels\n        truth_labels = truth_labels[filtering_selections]\n        print(f\"After filtering, {edge_index.shape[1]:,} edges remain\")\n\n        # apply the GNN to the filtered edges\n        if self.gnn_model is not None:\n            node_features = self.gnn_model.hparams[\"node_features\"]\n            node_scales = self.gnn_model.hparams[\"node_scales\"]\n            features = self.data_reader.get_node_features(node_features, node_scales)\n            self._print_memory_usage(\"After Retrieving GNN Node features\")\n\n            # get the senders and recievers\n            senders, receivers = features[edge_index[0]], features[edge_index[1]]\n            self._print_memory_usage(\"After Splitting Node features\")\n\n            # gnn inference\n            gnn_edge_scores = self.gnn_model.forward(senders, receivers)\n            self._print_memory_usage(\"After GNN\")\n            # apply sigmoid\n            gnn_edge_scores = torch.sigmoid(gnn_edge_scores)\n\n            # evaluate the edge scores\n            gnn_perf = self.edge_perf.eval_edge_scores(\n                gnn_edge_scores, truth_labels, outname=f\"perf_gnn_evt{evtid}\"\n            )\n\n        return dict(\n            edge_index=edge_index,\n            truth_labels=truth_labels,\n            true_edges=true_edges,\n            filter_edge_scores=filter_edge_scores,\n            per_edge_efficiency_embedding=per_edge_efficiency,\n            per_edge_purity_embedding=per_edge_purity,\n            filter_perf=filter_perf,\n            gnn_perf=gnn_perf,\n        )\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.model_inference.ExaTrkxInference.__call__","title":"<code>__call__(evtid, filter_cut=0.57, save_output=False, *args, **kwargs)</code>","text":"Source code in <code>src/heptracktool/tools/model_inference.py</code> <pre><code>def __call__(\n    self, evtid, filter_cut: float = 0.57, save_output: bool = False, *args, **kwargs\n):\n    self._print_memory_usage(\"Start\")\n\n    _ = self.data_reader.read(evtid)\n    self._print_memory_usage(\"After reading data\")\n    # embedding\n    node_features = self.embedding_model.hparams[\"node_features\"]\n    node_scales = self.embedding_model.hparams[\"node_scales\"]\n    features = self.data_reader.get_node_features(node_features, node_scales)\n    with torch.no_grad():\n        embedding = self.embedding_model.forward(features).detach()\n    self._print_memory_usage(\"After embedding\")\n\n    # FRNN\n    r_max = self.embedding_model.hparams[\"r_infer\"]\n    k_max = self.embedding_model.hparams[\"knn_infer\"]\n    knn_backend = self.embedding_model.hparams[\"knn_backend\"]\n    edge_index = build_edges(embedding, r_max=r_max, k_max=k_max, backend=knn_backend)\n    self._print_memory_usage(\"After FRNN\")\n    # edge-level performance\n    (\n        truth_labels,\n        true_edges,\n        per_edge_efficiency,\n        per_edge_purity,\n    ) = self.edge_perf.eval(edge_index)\n    self._print_memory_usage(\"After Edge Evaluation\")\n\n    # fetching filtering node features\n    node_features = self.filtering_model.hparams[\"node_features\"]\n    node_scales = self.filtering_model.hparams[\"node_scales\"]\n    features = self.data_reader.get_node_features(node_features, node_scales)\n    self._print_memory_usage(\"After Retrieving Filtering Node features\")\n\n    # get the senders and recievers\n    batch_size = self.filtering_model.hparams[\"batch_size\"]\n    senders, receivers = features[edge_index[0]], features[edge_index[1]]\n    self._print_memory_usage(\"After Splitting Node features\")\n\n    # filtering inference\n    filter_edge_scores = batched_inference(\n        self.filtering_model, senders, receivers, batch_size=batch_size\n    )\n    self._print_memory_usage(\"After Filtering\")\n    # apply sigmoid\n    filter_edge_scores = torch.sigmoid(filter_edge_scores)\n\n    # weights = self.data_reader.data.weights if \"weights\" in self.data_reader.data else None\n    # evaluate the edge scores\n    filter_perf = self.edge_perf.eval_edge_scores(\n        filter_edge_scores,\n        truth_labels,\n        outname=f\"perf_filtering_evt{evtid}\",\n    )\n\n    # obtain a threshold that gives 99% efficiency\n    # threshold = filter_perf[-1]\n    threshold = filter_cut\n    filtering_selections = filter_edge_scores &gt; threshold\n    edge_index = edge_index[:, filtering_selections]\n    # update the truth labels\n    truth_labels = truth_labels[filtering_selections]\n    print(f\"After filtering, {edge_index.shape[1]:,} edges remain\")\n\n    # apply the GNN to the filtered edges\n    if self.gnn_model is not None:\n        node_features = self.gnn_model.hparams[\"node_features\"]\n        node_scales = self.gnn_model.hparams[\"node_scales\"]\n        features = self.data_reader.get_node_features(node_features, node_scales)\n        self._print_memory_usage(\"After Retrieving GNN Node features\")\n\n        # get the senders and recievers\n        senders, receivers = features[edge_index[0]], features[edge_index[1]]\n        self._print_memory_usage(\"After Splitting Node features\")\n\n        # gnn inference\n        gnn_edge_scores = self.gnn_model.forward(senders, receivers)\n        self._print_memory_usage(\"After GNN\")\n        # apply sigmoid\n        gnn_edge_scores = torch.sigmoid(gnn_edge_scores)\n\n        # evaluate the edge scores\n        gnn_perf = self.edge_perf.eval_edge_scores(\n            gnn_edge_scores, truth_labels, outname=f\"perf_gnn_evt{evtid}\"\n        )\n\n    return dict(\n        edge_index=edge_index,\n        truth_labels=truth_labels,\n        true_edges=true_edges,\n        filter_edge_scores=filter_edge_scores,\n        per_edge_efficiency_embedding=per_edge_efficiency,\n        per_edge_purity_embedding=per_edge_purity,\n        filter_perf=filter_perf,\n        gnn_perf=gnn_perf,\n    )\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy","title":"<code>SparcifyStudy</code>","text":"Source code in <code>src/heptracktool/tools/sparcification_study.py</code> <pre><code>class SparcifyStudy:\n    def __init__(\n        self,\n        metric_learning_ckpt_filename,\n        pyg_reader: TrackGraphDataReader,\n        kval: int | None = None,\n        rval: float | None = None,\n        device: str | None = None,\n    ):\n        self.model = MetricLearning.load_from_checkpoint(metric_learning_ckpt_filename)\n        self.reader = pyg_reader\n        self.edge_perf = EdgePerformance(self.reader)\n\n        self.node_features = self.model.hparams[\"node_features\"]\n        self.node_scales = self.model.hparams[\"node_scales\"]\n\n        self.kval = self.model.hparams[\"knn_val\"] if kval is None else kval\n        self.rval = self.model.hparams[\"r_train\"] if rval is None else rval\n        self.device = (\n            device if device is not None else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        )\n        self.model.to(self.device)\n        self.model.eval()\n\n        logger.info(f\"# of node features: {len(self.node_features)}\")\n        logger.info(f\"Node features: {self.node_features}\")\n        logger.info(f\"Node scales: {self.node_scales}\")\n        logger.info(f\"KNN neighbours: {self.kval}\")\n        logger.info(f\"KNN radius: {self.rval}\")\n\n    def build_knn_graph(\n        self, input_pyg_filename: str, kval: int | None = None, rval: float | None = None\n    ) -&gt; sp.coo_matrix:\n        self.reader.read_by_filename(input_pyg_filename)\n\n        kval = kval if kval is not None else self.kval\n        rval = rval if rval is not None else self.rval\n\n        in_features = self.reader.get_node_features(self.node_features, self.node_scales).to(\n            self.device\n        )\n\n        num_nodes = in_features.size(0)\n        with torch.no_grad():\n            embedding = self.model(in_features)\n        knn_backend = \"FRNN\" if self.device == \"cuda\" else \"torch\"\n        edge_index = build_edges(embedding, None, rval, kval, backend=knn_backend)\n\n        # sort the edges and remove duplicated.\n        edge_index[:, edge_index[0] &gt; edge_index[1]] = edge_index[\n            :, edge_index[0] &gt; edge_index[1]\n        ].flip(0)\n        edge_index = torch.unique(edge_index, dim=-1)\n\n        # Treat the embedding distances between the edges as weights\n        weights = torch.norm(embedding[edge_index[0]] - embedding[edge_index[1]], dim=1)\n        sparse_matrix = sp.coo_matrix(\n            (weights.cpu().numpy(), edge_index.cpu().numpy()), shape=(num_nodes, num_nodes)\n        )\n        return sparse_matrix\n\n    def eval_sparcification(\n        self, sp_coo_matrix: sp.coo_matrix, input_pyg_filename: str | None = None\n    ) -&gt; Any:\n        if input_pyg_filename is not None:\n            self.reader.read_by_filename(input_pyg_filename)\n        elif self.reader.data is None:\n            raise ValueError(\n                \"No data loaded. Please run self.reader.read_by_filename(filename) first.\"\n            )\n\n        array = np.array([sp_coo_matrix.row, sp_coo_matrix.col], dtype=int)\n        edge_index = torch.from_numpy(array)\n        # make the graph undirected.\n        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=-1)\n        print(f\"Number of edges: {edge_index.size(1):,}\")\n        return self.edge_perf.eval(edge_index)\n\n    def read_sparse_matrix(self, input_filename: str) -&gt; sp.coo_matrix:\n        return mmread(input_filename)\n\n    def save_sparse_matrix(self, sparse_matrix: sp.coo_matrix, output_filename: str):\n        mmwrite(output_filename, sparse_matrix)\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.device","title":"<code>device = device if device is not None else 'cuda' if torch.cuda.is_available() else 'cpu'</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.edge_perf","title":"<code>edge_perf = EdgePerformance(self.reader)</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.kval","title":"<code>kval = self.model.hparams['knn_val'] if kval is None else kval</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.model","title":"<code>model = MetricLearning.load_from_checkpoint(metric_learning_ckpt_filename)</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.node_features","title":"<code>node_features = self.model.hparams['node_features']</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.node_scales","title":"<code>node_scales = self.model.hparams['node_scales']</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.reader","title":"<code>reader = pyg_reader</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.rval","title":"<code>rval = self.model.hparams['r_train'] if rval is None else rval</code>  <code>instance-attribute</code>","text":""},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.__init__","title":"<code>__init__(metric_learning_ckpt_filename, pyg_reader, kval=None, rval=None, device=None)</code>","text":"Source code in <code>src/heptracktool/tools/sparcification_study.py</code> <pre><code>def __init__(\n    self,\n    metric_learning_ckpt_filename,\n    pyg_reader: TrackGraphDataReader,\n    kval: int | None = None,\n    rval: float | None = None,\n    device: str | None = None,\n):\n    self.model = MetricLearning.load_from_checkpoint(metric_learning_ckpt_filename)\n    self.reader = pyg_reader\n    self.edge_perf = EdgePerformance(self.reader)\n\n    self.node_features = self.model.hparams[\"node_features\"]\n    self.node_scales = self.model.hparams[\"node_scales\"]\n\n    self.kval = self.model.hparams[\"knn_val\"] if kval is None else kval\n    self.rval = self.model.hparams[\"r_train\"] if rval is None else rval\n    self.device = (\n        device if device is not None else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    )\n    self.model.to(self.device)\n    self.model.eval()\n\n    logger.info(f\"# of node features: {len(self.node_features)}\")\n    logger.info(f\"Node features: {self.node_features}\")\n    logger.info(f\"Node scales: {self.node_scales}\")\n    logger.info(f\"KNN neighbours: {self.kval}\")\n    logger.info(f\"KNN radius: {self.rval}\")\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.build_knn_graph","title":"<code>build_knn_graph(input_pyg_filename, kval=None, rval=None)</code>","text":"Source code in <code>src/heptracktool/tools/sparcification_study.py</code> <pre><code>def build_knn_graph(\n    self, input_pyg_filename: str, kval: int | None = None, rval: float | None = None\n) -&gt; sp.coo_matrix:\n    self.reader.read_by_filename(input_pyg_filename)\n\n    kval = kval if kval is not None else self.kval\n    rval = rval if rval is not None else self.rval\n\n    in_features = self.reader.get_node_features(self.node_features, self.node_scales).to(\n        self.device\n    )\n\n    num_nodes = in_features.size(0)\n    with torch.no_grad():\n        embedding = self.model(in_features)\n    knn_backend = \"FRNN\" if self.device == \"cuda\" else \"torch\"\n    edge_index = build_edges(embedding, None, rval, kval, backend=knn_backend)\n\n    # sort the edges and remove duplicated.\n    edge_index[:, edge_index[0] &gt; edge_index[1]] = edge_index[\n        :, edge_index[0] &gt; edge_index[1]\n    ].flip(0)\n    edge_index = torch.unique(edge_index, dim=-1)\n\n    # Treat the embedding distances between the edges as weights\n    weights = torch.norm(embedding[edge_index[0]] - embedding[edge_index[1]], dim=1)\n    sparse_matrix = sp.coo_matrix(\n        (weights.cpu().numpy(), edge_index.cpu().numpy()), shape=(num_nodes, num_nodes)\n    )\n    return sparse_matrix\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.eval_sparcification","title":"<code>eval_sparcification(sp_coo_matrix, input_pyg_filename=None)</code>","text":"Source code in <code>src/heptracktool/tools/sparcification_study.py</code> <pre><code>def eval_sparcification(\n    self, sp_coo_matrix: sp.coo_matrix, input_pyg_filename: str | None = None\n) -&gt; Any:\n    if input_pyg_filename is not None:\n        self.reader.read_by_filename(input_pyg_filename)\n    elif self.reader.data is None:\n        raise ValueError(\n            \"No data loaded. Please run self.reader.read_by_filename(filename) first.\"\n        )\n\n    array = np.array([sp_coo_matrix.row, sp_coo_matrix.col], dtype=int)\n    edge_index = torch.from_numpy(array)\n    # make the graph undirected.\n    edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=-1)\n    print(f\"Number of edges: {edge_index.size(1):,}\")\n    return self.edge_perf.eval(edge_index)\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.read_sparse_matrix","title":"<code>read_sparse_matrix(input_filename)</code>","text":"Source code in <code>src/heptracktool/tools/sparcification_study.py</code> <pre><code>def read_sparse_matrix(self, input_filename: str) -&gt; sp.coo_matrix:\n    return mmread(input_filename)\n</code></pre>"},{"location":"api/heptracktool/tools/#heptracktool.tools.sparcification_study.SparcifyStudy.save_sparse_matrix","title":"<code>save_sparse_matrix(sparse_matrix, output_filename)</code>","text":"Source code in <code>src/heptracktool/tools/sparcification_study.py</code> <pre><code>def save_sparse_matrix(self, sparse_matrix: sp.coo_matrix, output_filename: str):\n    mmwrite(output_filename, sparse_matrix)\n</code></pre>"}]}